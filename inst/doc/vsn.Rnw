%\VignetteIndexEntry{Introduction to vsn}
%\VignetteDepends{Biobase,vsn,affy,affydata,marray,multtest,limma,hgu95av2cdf}
%\VignetteKeywords{Expression Analysis}
%\VignettePackage{vsn}

\documentclass[11pt]{article}
\usepackage{geometry}\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\usepackage[%
baseurl={http://www.bioconductor.org},%
pdftitle={Introduction to robust calibration and variance stabilization with vsn},%
pdfauthor={Wolfgang Huber},%
pdfsubject={vsn},%
pdfkeywords={Bioconductor},%
pagebackref,bookmarks,colorlinks,linkcolor=darkblue,citecolor=darkblue,%
pagecolor=darkblue,raiselinks,plainpages,pdftex]{hyperref}

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\arsinh}{\mathop{\mathgroup\symoperators arsinh}\nolimits}
\newcommand{\glog}{\mathop{\mathgroup\symoperators glog}\nolimits}
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{{\small\texttt{#1}}}

\newcommand{\myincfig}[3]{%
  \begin{figure}[htbp]
    \begin{center}
      \includegraphics[width=#2]{#1}
      \caption{\label{#1}#3}
    \end{center}
  \end{figure}
}

\begin{document}

%----------------------------------------------------------------------------------------
\title{Introduction to robust calibration and variance stabilization with \Rpackage{vsn}}
%----------------------------------------------------------------------------------------
\author{Wolfgang Huber}
\maketitle
\tableofcontents

<<setup,echo=FALSE,results=hide>>=
library("affy")
library("marray")
library("multtest")
library("limma")
library("vsn")
@ 

%------------------------------------------------------------
\section{Getting started: a brief overview}\label{sec:overv}
%------------------------------------------------------------ 
\Rpackage{vsn} is a method to preprocess microarray intensity data.
This can be as simple as
%
<<overv1, results=hide>>=
library("vsn")
data("kidney")
xnorm = justvsn(kidney)
@
%
where \Robject{kidney} is an \Rclass{ExpressionSet} object with
unnormalized data and \Robject{xnorm} the resulting
\Rclass{ExpressionSet} with calibrated and $\glog_2$-transformed
data.
%
<<overv2>>=
M <- exprs(xnorm)[,1] - exprs(xnorm)[,2]
@
%
produces the vector of generalized log-ratios between the 
data in the first and second column.

\Rpackage{vsn} is a \emph{model-based} method, and the more explicit way of 
doing the above task is
%
<<overv3, results=hide>>=
fit = vsn2(kidney)
ynorm = predict(fit, kidney)
@
%
where \Robject{fit} is an object of class \Rclass{vsn} that contains
the fitted calibration and transformation parameters (see
Section~\ref{sec:calib} for more details on these).  The method
\Rfunction{predict} can be used to apply the fit to the data. Often,
there is no need for making these separate steps explicit, and that is
why there is the function \Rfunction{justvsn}. 
\Robject{xnorm} and \Robject{ynorm} are identical.
The two-step protocol
is useful when you want to fit the parameters on a
subset of the data, e.\,g.\ a set some control or spike-in features,
and then apply the model to the complete set of data. Furthermore, it
allows further inspection of the \Robject{fit} object, e.\,g.\ for the
purposes of quality assessment.
%
@ 
<<overv5, echo=FALSE, results=hide>>=
stopifnot(identical(exprs(xnorm), exprs(ynorm)), identical(exprs(xnorm), exprs(fit)))
@ 
%
Beside \Rclass{ExpressionSet}s, there 
\textit{will also be}
%are also 
methods for handling matrices, 
\Rclass{RGList} objects from the \Rpackage{limma} package and
\Rclass{AffyBatch} objects from the \Rpackage{affy} package.
\textit{FIXME: this vignette and the package are currently (Jan-Mar 2007) 
being revised, some sections may be broken or incomplete, please bear 
with me, I intend to fix all this for the 2.0 release.}

The so-called $\glog_2$ (short for \textit{\textbf{generalized logarithm}}) 
is a function that is like the logarithm (to base 2) for large values 
(large compared to the amplitude of the background noise),
but is less steep for smaller values.  Differences between the transformed
values are the \textit{\textbf{generalized log-ratios}}. These are 
\emph{shrinkage estimators} of the logarithm of the fold change.
The usual \emph{log-ratio} is another example for an estimator\footnote{%
In statistics, the term \emph{estimator} is used to denote an algorithm
that calculates a value from a set of measured data. 
This value is intended to correspond to a parameter of the 
underlying distribution that generated the data. Depending on the amount of the 
available data and the quality of the estimator, the 
correspondence between the estimated value and the true value may be more 
or less faithful. For example, the arithmetic mean and the median are two 
different estimators of the expectation value of a distribution.}
of log fold change. 
There is also a close relationship between \emph{background correction} of 
the intensities and the variance properties of these different estimators. Please
see Section~\ref{sec:shrink} for more explanation of these issues. 

How does \Rpackage{vsn} work? In short, each column is calibrated by
an affine transformation\footnote{It is possible to stratify the
transformations within columns, see the \Robject{strata} parameter of
\Rfunction{vsn}.}, then the whole data are transformed by a logarithm-like
variance-stabilizing transformation.  After this, systematic array- or
dye-biases should be removed, and the variance should be approximately
independent of the mean intensity.  Many statistical methods such as
hypothesis tests, ANOVA modeling, clustering, or classification work
better or are easier to use if the variance of the data is roughly the
same for all observations\footnote{Note that \Rpackage{vsn} only
addresses the dependence of the variance on the mean intensity. There
may be other factors influencing the variance, such as gene-inherent
properties, or changes of the tightness of transcriptional control in
different conditions.  If necessary, these need to be addressed by
other methods.}.

%------------------------------------------------------------
\section{Running vsn on data from a single two-color array} 
%------------------------------------------------------------
The dataset \Robject{kidney} from Section~\ref{sec:overv} contains
example data from a single cDNA array on which two biologically
similar samples, one labeled in green (Cy3), one in red (Cy5), were
hybridized.  The two columns of the matrix \Robject{exprs(kidney)}
contain the green and red intensities, respectively. A local 
background estimate\footnote{%
See Section~\ref{sec:shrink} for more on the relationship between 
background correction and variance stabilizing transformations.} 
was calculated by the image analysis software and subtracted, hence 
some of the intensities in \Robject{kidney} are close to zero or 
negative. In
Figure~\ref{vsn-nkid-scp} you can see the scatterplot of the
calibrated and transformed data. For comparison, the scatterplot of
the log-transformed raw intensities is also shown.
%
<<nkid-scp,include=FALSE,fig=TRUE,width=8,height=4>>=
par(mfrow=c(1,2))
select <- 0==rowSums(exprs(kidney)<=0)
plot(exprs(xnorm), main = "a) vsn", pch = ".", col=ifelse(select, "black", "orange"))
plot(log2(exprs(kidney)[select, ]), main = "b) raw", pch = ".")
@
\myincfig{vsn-nkid-scp}{\textwidth}{%
Scatterplots of the kidney example data. 
a) normalized and transformed with \Rpackage{vsn}, 
b) original data, $\log_2$-transformed.
Panel a shows the data from the complete set of \Sexpr{nrow(kidney)} 
spots on the array, panel b only the \Sexpr{sum(select)} spots for which
\Robject{select} (see code chuck in the main text) is \Robject{TRUE}. 
Those spots which are missing in panel b are colored in orange in panel a.}
%
To verify the variance
stabilization, there is the function \Robject{meanSdPlot}. For each
probe $k=1,\ldots,n$ it shows the estimated standard deviation
$\hat{\sigma}_k$ on the $y$-axis versus the rank of the average
$\hat{\mu}_k$ on the $x$-axis,
\begin{equation}
\hat{\mu}_k     =\frac{1}{d}  \sum_{i=1}^d h_{ki}\quad\quad
\hat{\sigma}_k^2=\frac{1}{d-1}\sum_{i=1}^d (h_{ki}-\hat{\mu}_k)^2.
\end{equation}
<<nkid-sdmean,include=FALSE,fig=TRUE,width=8,height=4,results=hide>>=
par(mfrow=c(1,2))
meanSdPlot(xnorm, ranks=TRUE)
meanSdPlot(xnorm, ranks=FALSE)
@
\myincfig{vsn-nkid-sdmean}{\textwidth}{Standard deviation versus rank
of the mean, and the mean, respectively}
Such a plot is shown in Fig.~\ref{vsn-nkid-sdmean}.  The red dots,
connected by lines, show the running median of the standard
deviation\footnote{Window width: 10\%, window midpoints 5\%, 10\%,
15\%, \ldots.}. Within each window, the median may be considered a
pooled estimator of the standard deviation, and the curve given by the
red line is an estimate of the systematic dependence of the standard
deviation on the mean. After variance stabilization, this should be
approximately a horizontal line.  It may have some random
fluctuations, but should not show an overall trend.  If this is not
the case, that usually indicates a data quality problem, or is a
consequence of inadequate prior data preprocessing. 
The rank ordering distributes the data evenly
along the $x$-axis. A plot in which the $x$-axis shows the average
intensities themselves is obtained by calling the \Robject{plot}
command with the argument \Robject{ranks=FALSE}.

The histogram of the \Robject{M}-values is shown in 
Figure~\ref{vsn-nkid-histM}.
%
<<nkid-histM,include=FALSE,echo=FALSE,fig=TRUE,results=hide,width=5,height=5>>=
hist(M, breaks=50, col="#d95f0e")
@
\myincfig{vsn-nkid-histM}{0.4\textwidth}{Histogram of generalized 
log-ratios \Robject{M} for the kidney example data.}

%------------------------------------------------------------
\section{Running vsn on data from multiple arrays 
(``single color normalization'')} 
%------------------------------------------------------------
The package includes example data from a series of 8 cDNA arrays 
on which different lymphoma were hybridized together with a reference 
cDNA~\cite{Alizadeh}.
<<lymphoma>>=
data(lymphoma)
dim(exprs(lymphoma))
pData(lymphoma)
@
The 16 columns of the \Robject{lymphoma} object contain the red and
green intensities, respectively, from the 8 slides, as shown in the
table. Thus, the CH1 intensities are in columns $1, 3, \ldots, 15$,
the CH2 intensities in columns $2, 4, \ldots, 16$.  We can call
\Robject{vsn} on all of them at once:
<<lym-sdmean1,results=hide>>=
lym <- vsn(lymphoma)
@
This calculation may take a while. 
<<lym-sdmean2,include=FALSE,fig=TRUE>>=
meanSdPlot(lym)
@
\myincfig{vsn-lym-sdmean2}{0.5\textwidth}{Standard deviation 
versus rank of the mean for the lymphoma example data}
Again, Fig.~\ref{vsn-lym-sdmean2} helps to visually verify that the
variance stabilization worked.  As above, we can obtain the
generalized log-ratios for each slide, by subtracting the common
reference intensities from those for the 8 samples:
<<lym-M,include=FALSE,fig=TRUE,width=8,height=4,results=hide>>=
refrs <- (1:8)*2-1
samps <- (1:8)*2
M <- exprs(lym)[,samps] - exprs(lym)[,refrs] 
colnames(M) <-  pData(lymphoma)[samps, "sample"]
A <- rowMeans(exprs(lym))
par(mfrow=c(1,2))
plot(A, M[,"CLL-13"], pch=".")
abline(h=0, col="red")
plot(A, M[,"DLCL-0032"], pch=".")
abline(h=0, col="red")
@
\myincfig{vsn-lym-M}{\textwidth}{Mean-difference plots for two slides 
from the lymphoma example data}
Fig.~\ref{vsn-lym-M} shows the analagon to the $M$-vs-$A$-plots
as described in reference~\cite{Dudoit578}. Note that in the left
scatterplot, there is a cloud of points at low intensities that is
concentrated slightly off the line $M=0$.  In the right scatterplot, a
similar cloud sits right on the $M=0$ line. This could be related to a
quality problem with the left slide (e.\,g. related to the PCR
amplification or the printing, see Section~\ref{sec.qc}).

%---------------------------------------------------------
\section{Running vsn on Affymetrix data} \label{affy}
%---------------------------------------------------------
The package \Rpackage{affy} provides excellent functionality for
reading and processing Affymetrix genechip data. To use
\Robject{vsn} for the calibration and transformation of the probe
intensities, a wrapper is provided that can be used within the data
processing routines of \Rpackage{affy}. See the documentation for the
package \Rpackage{affy} for more information about data structures and
other available methods. Affymetrix genechips preprocessing involves
the following steps:
(i) combining the perfect match (PM) and mismatch 
(MM) intensities into one number per probe,
(ii) calibrating,
(iii) transforming, and
(iv) summarizing.
\Robject{vsn} addresses the calibration and transformation. We can use 
the function \Robject{expresso} to run the whole process in one go:

%% FIXME
<<affy1,results=hide,eval=FALSE>>=
library("affy")
library("affydata")
data("Dilution")
## let affy know about vsn
normalize.AffyBatch.methods <- c(normalize.AffyBatch.methods, "vsn")
es1 = expresso(Dilution[, 1:2], 
               bg.correct       = FALSE,   ## bg correction is done by vsn
               normalize.method = "vsn",
               pmcorrect.method = "pmonly", 
               summary.method   = "medianpolish")
@

Here, we have ignored the MM values and used \Robject{medianpolish} for
summarization, as in the RMA method~\cite{RMA}. For comparison, let's 
calculate expression values using another normalization method.
The resulting plots are shown in Fig.~\ref{vsn-affy3}.

%%FIXME
<<affy2,results=hide,eval=FALSE>>=
es2 = expresso(Dilution[, 1:2], 
               bgcorrect.method = "rma",
               normalize.method = "quantiles", 
               pmcorrect.method = "pmonly",
               summary.method   = "medianpolish")
## extract expression values
x1 = exprs(es1)
x2 = exprs(es2) 
@ 

%%FIXME
<<dummy>>=
x1=x2=matrix(runif(1000), ncol=2)
@ 

<<affy3,include=FALSE,fig=TRUE,width=7,height=7>>=
## graphics output
par(mfrow=c(2,2), pch=".")

## scatter plot
plot(x1, main="vsn: chip 3 vs 4")
plot(x2, main="rma: chip 3 vs 4")

## rank(mean) - difference plot
ylim = c(-0.7, 0.7)
plot(rank(rowSums(x1)), diff(t(x1)), ylim=ylim, main="rank(mean) vs differences")
abline(h=0, col="red")

plot(rank(rowSums(x2)), diff(t(x2)), ylim=ylim, main="rank(mean) vs differences")
abline(h=0, col="red")
@

Note that while the values of \Rpackage{vsn} are normally represented on the
natural logarithmic scale, with the wrapper \Rfunction{normalize.AffyBatch.vsn}
they are transformed to the logarithm base 2 scale. This way
\Rfunction{normalize.AffyBatch.vsn} fits into the conventions of the
\Rpackage{expresso}-function.

\myincfig{vsn-affy3}{\textwidth}{\Robject{normalize.AffyBatch.vsn} example}

%---------------------------------------------------------
\section{Running vsn from the limma package} \label{limma}
%---------------------------------------------------------
\Robject{vsn} can be called from the limma package through the
function \Robject{normalizeBetweenArrays}:

<<limma1, results=hide>>= 
library("limma")
lymRG = new("RGList", list(
          R=exprs(lymphoma)[, lymphoma$dye=="Cy5"],
          G=exprs(lymphoma)[, lymphoma$dye=="Cy3"]))
lymMA <- normalizeBetweenArrays(lymRG, method="vsn")
@


<<limma2, echo=FALSE, results=hide>>=
lmat <- normalizeBetweenArrays(exprs(lymphoma), method="vsn")
lmatM <-  lmat[, lymphoma$dye=="Cy3"]-lmat[, lymphoma$dye=="Cy5"]
lmatA <- (lmat[, lymphoma$dye=="Cy3"]+lmat[, lymphoma$dye=="Cy5"])/2
tol = 1e-2
print(max(abs(lymMA$A-lmatA))<tol, max(abs(lymMA$M-lmatM)))
@ 

\textbf{FIXME}: 1. comment on background estimates (Rb, Gb)
2. test the print-tip specific normalization call.

Note that \Robject{RG} should contain raw intensities, i.\,e., prior
log-transformation or any normalization. The returned intensities and
log-ratios in \Robject{MA} are on the $\log-2$ scale, not the $\log-e$
scale as when \Robject{vsn} is called directly. Please see also the
help page for \Robject{normalizeBetweenArrays}.

For print-tip wise normalization, construct a function
\Robject{pinId} that calculates the print-tip ID (1...16) for every
spot:

<<limma2,eval=FALSE>>=
pinId <- function(x)
  unlist(lapply(1:(x$ngrid.r*x$ngrid.c), rep, x$nspot.r*x$nspot.c))
@

and call
<<limma3,eval=FALSE>>=
MA <- normalizeBetweenArrays(RG, method="vsn", strata=pinId(thelayout))
@


%---------------------------------------------------------------------
\section{The calibration parameters} \label{sec:calib}
%---------------------------------------------------------------------
If $y_{ki}$ is the matrix of uncalibrated data, with $k$ indexing the
rows and $i$ the columns, then the calibrated data $y_{ki}'$ is
obtained through scaling by $\lambda_{si}$ and shifting by $o_{si}$:
\begin{equation}\label{eq.cal}
y_{ki}' = \frac {y_{ki}-o_{si}}{\lambda_{si}},
\end{equation}
where $s\equiv s(k)$ is the so-called \textit{stratum} for probe $k$. In the
simplest case, there is only one stratum, i.\,e.\ the index $s$ is always
equal to 1, or may be omitted altogether. This amounts to assuming that 
that the data of all probes on an array were subject to the same 
systematic effects, such that an array-wide calibration is sufficient.

A model with multiple strata per array may be useful for spotted
arrays. For these, stratification may be according to
print-tip~\cite{Dudoit578} or PCR-plate~\cite{HSG2002}. For
oligonucleotide arrays, it may be useful to stratify the probes by
physico-chemical properties, e.\,g.\, to assume that probes of
different sequence composition attract systematically different levels
of unspecific background signal.

The transformation to a scale where the variance of the data is approximately
independent of the mean is 
\begin{equation}\label{eq.vs}
h_{ki} = \arsinh(a_0+b_0y_{ki}') 
  = \log\left(a_0+b_0y_{ki}'+\sqrt{\left(a_0+b_0y_{ki}'\right)^2+1}\right).
\end{equation}
Eqns.~(\ref{eq.cal}) and (\ref{eq.vs}) can be combined, so that the whole 
transformation is given by 
\begin{equation}\label{eq.transf}
h_{ki} = \arsinh(a_{si} + b_{si} y_{ki}). 
\end{equation}
Here, $a_{si}=a_0-b_0o_{si}/\lambda_{si}$ and $b_{si}=b_0/\lambda_{si}$ 
are the combined calibation and transformation parameters for probes from
stratum $s$ and sample $i$.

We can access the calibration and transformation parameters through
<<nkid-calib1>>=
fit@par
@
% 
For a dataset with $d$ samples and $s$ strata,
\Robject{fit@par} is a numeric array with dimensions $(s, d, 2)$. 
For the example data that was used in Section~\ref{sec:overv} to generate 
\Robject{fit}, $d=2$ and $s=1$.
\Robject{fit@par[s, i, 1]}, the first line in the results of the above code chunk, 
is what was called $a_{si}$ in Eqn.~(\ref{eq.transf}), and
\Robject{fit@par[s, i, 2]}, the second line, is $b_{si}$. 

%---------------------------------------------------------------------
\subsection{More on calibration} 
%---------------------------------------------------------------------
Now suppose the kidney example data were not that well measured, and 
the red channel had a baseline that was shifted by 500 and a scale 
that differed by a factor of $0.25$:
<<nkid-calib2>>=
bkid <- kidney
exprs(bkid)[,"red"] <- 0.25 * (500+exprs(bkid)[,"red"])
@
We can again call \Robject{vsn} on this data
<<nkid-calib-warn1,echo=FALSE,results=hide>>=
oldwarn <- options(warn=-1)
@
<<nkid-calib3,results=hide>>=
nbkid <- vsn(bkid)
<<nkid-calib4,fig=TRUE,include=FALSE,width=8,height=4>>=
par(mfrow=c(1,2))
plot(exprs(bkid),  main = "raw", pch = ".", log="xy")
plot(exprs(nbkid), main = "vsn", pch = ".")
preproc(description(nbkid))$vsnParams[1,,]
@
% $ for ESS
\myincfig{vsn-nkid-calib4}{\textwidth}{Scatterplots for badly biased 
data. Left hand side: raw data on log-log scale, right hand side: after 
calibration and transformation with vsn.}
<<nkid-calib-warn2,echo=FALSE,results=hide>>=
options(oldwarn)
rm(oldwarn)
@
The factor for the red channel is now about four times as large as
before.  The result is shown in Fig.~\ref{vsn-nkid-calib4}.


%-------------------------------------------------------------------
\section{Assessing vsn and comparing it to other methods}
%-------------------------------------------------------------------
The function \Robject{vsn} is a parameter estimation algorithm that fits the
parameters for a certain model. In order to see how good the estimator is, we
can look at bias, variance, sample size dependence, robustness against model
misspecificaton and outliers. This is done in the document
\texttt{convergence.pdf}, which can be found in the \texttt{doc} subdirectory
of the package.

Practically, the more interesting question is how different microarray
calibration and data transformation methods compare to each other. For this,
one needs to specify a measure of goodness. One approach is to compare the
obtained values against a known truth. This can be done in controlled spike-in
experiments and in dilution series, which allow to systematically assess the
performance of the methods at different biologically relevant spike-in
concentrations. Like any statistical method, one can make different choices
with respect to the trade-off between bias and variance~\cite{Affycomp}.

Here, we focus on one particular aspect: the overall sensitivity and
specificity in detecting differential transcription. The following
type of analysis can be applied to any data set that contains
replicated measurements made on samples from biologically distinct,
known groups. The idea is that we compare the within-group variability
(among the biological replicates) to the between-group variability
(between different tissue types). The smaller the former and the
larger the latter, the better we may deem the performance of the
calibration and data transformation.

Here, as a measure of the relative size of between- and within-group
variability we take the size of the $t$-statistics.  The acceptable
use of CPU time and disk memory of a package vignette is limited, thus
here we stick to a very simple-minded calculation, and a small data
set. See Fig.~\ref{fig-comp} and the calculations below. Two
applications to larger data sets are described in
reference~\cite{HuberISMB2002}.  More sophisticated analyses can be
made by comparing not just the distributions of $t$-statistics, but
for example, the estimated false discovery rates, using different test
statistics. You are encouraged to try this out with your own data.
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{vsn-comp}
\caption{\label{fig-comp}Left hand side: $x$-axis -- generalized
log-ratios for slide 1 from \Robject{vsn}, $y$-axis -- log-ratios
for slide 1 after global median normalization. For most genes, the two
are the same, but in some cases the generalized log-ratio is smaller.
It is never larger. This demonstrates the \textit{ratio shrinkage} by
the variance stabilization. Right hand side: quantile-quantile-plot of
the $t$-statistic for the comparison between the 4 slides with CLL and
the 4 with DLCL. The $t$-statistics from \Robject{vsn} are larger,
i.\,e.\ it compares more favorable with respect to the relative size
of between- and within-group variability.}
\end{center}
\end{figure}

<<marraynorm,results=hide>>=
library("marray")
mr <- new('marrayRaw', 
          maGf=exprs(lymphoma)[,refrs], 
          maRf=exprs(lymphoma)[,samps],
          maLayout=new('marrayLayout', maNgr=4, maNgc=4, maNsr=24, maNsc=24))
mn <- maNorm(mr, norm="median", echo=TRUE)
@
<<comp,results=hide,fig=TRUE,width=8,height=4,include=FALSE>>=
par(mfrow=c(1,2))
library("multtest")
plot(M[,1], mn@maM[,1]*log(2), xlab="M (vsn)", ylab="M (global median)", main="slide 1", pch=".")
abline(a=0,b=1,col="blue")
classlabel <- regexpr("CLL",colnames(M)) > 0
t1 <- mt.teststat(M, classlabel)
t2 <- mt.teststat(mn@maM, classlabel)
qqplot(t1, t2, xlab="t (vsn)", ylab="t (global median)", main="QQ plot", pch=".")
abline(a=0,b=1,col="blue")
@

%------------------------------------------------------------
\section{vsn, shrinkage and background correction} \label{sec:shrink}
%------------------------------------------------------------
%
<<calcshrink, echo=FALSE>>=
fc = 0.5
x2 = seq(0.5, 15, by=0.5)
x1 = x2/fc
m = s = numeric(length(x1))
n  = 20000
sa = 1
b  = 1
sb = 0.1
sdeta = 0.1
for(i in 1:length(x1)){
  z1 = sa*rnorm(n)+x1[i]*b*exp(sb*rnorm(n))
  z2 = sa*rnorm(n)+x2[i]*b*exp(sb*rnorm(n))
  if(i%%2==1) {
    q = log(z1/z2)
    m[i] = mean(q, na.rm=TRUE)
    s[i] = sd(q, na.rm=TRUE)
  } else {
    h = (asinh(z1/(sa*b/sb))-asinh(z2/(sa*b/sb)))
    m[i] = mean(h)
    s[i] = sd(h)
  }
}

colq = c("black", "blue")
lty  = 1
pch  = c(20,18)
cex  = 1.4
lwd  = 2
@ 
%
<<figshrink, fig=TRUE, echo=FALSE, include=TRUE, width=5, height=5>>=
mai  = par("mai"); mai[3]=0; par(mai)
plot(x2, m, ylim=c(-1.2,2), type="n", xlab=expression(x[2]), ylab="")
abline(h=-log(fc), col="red", lwd=lwd, lty=1)
abline(h=0, col="black", lwd=1, lty=2)
points(x2, m, pch=pch, col=colq, cex=cex)
segments(x2, m-2*s, x2, m+2*s, lwd=lwd, col=colq, lty=lty)
legend(8.75, -0.1, c("q","h"), col=colq, pch=pch, lty=lty, lwd=lwd)
@
%
\myincfig{vsn-figshrink}{0.5\textwidth}{%
The shrinkage property of the generalized log-ratio.  
Blue diamonds and error bars correspond to mean and standard
deviation of the generalized log-ratio $h$, as obtained from \Rpackage{vsn}, 
black dots and error bars to the naive log-ratio $q$.  
For this figure, data were simulated generated from the 
additive-multiplicative error model~\cite{RockeDurbin2001,HuberSAGMB2003,HuberWiley2004}.
The horizontal line corresponds to the true log-ratio $\log(2)\approx0.693$.
For intensities $x_2$ that are larger than about ten times the additive noise 
level $\sigma_a$, generalized log-ratio $h$ and naive log-ratio $q$ coincide. 
For smaller intensities, we can see a \textit{variance-bias trade-off}: 
$q$ has no bias but a huge variance, thus an estimate of the 
fold change based on a limited set of data can be arbitrarily off.
In contrast, $h$ keeps a constant variance -- for the 
price of systematically underestimating the true fold change.}

Generalized log-ratios can be viewed as a \textit{shrinkage estimator}: they
are always smaller than or equal to the naive log-ratios; equality is
asymptotically reached if the probe intensities are large both for samples $i$
and $j$. Their advantage is that they do not suffer from the variance
divergence of the naive log-ratios at small intensities: they remain
well-defined and statistically meaningful when the data come close to zero or
even become negative.  Please consult the references for more on the
mathematical-methodical background~\cite{HuberISMB2002,HSG2002,HuberSAGMB2003}.



%---------------------------------------------------------
\section{Quality assessment}\label{sec.qc}
%---------------------------------------------------------
\Robject{vsn} makes some assumptions about your data that need to
hold if it is to produce meaningful results. We have found them
appropriate for many microarray experiments, but it is your
responsibility to make sure that they hold for your data.

First, \Robject{vsn} assumes that the measured signal $y_{ik}$
increases, to sufficient approximation, proportionally to the mRNA
abundance $c_{ik}$ of gene $k$ on the $i$-th array, or on the $i$-th
color channel:
\begin{equation}\label{assumption.1} 
y_{ik}\approx a_i + b_i b_k c_{ik}.  
\end{equation} 
For a series of $d$ single-color arrays such as Affymetrix arrays
or cDNA nylon membranes, $i=1,\ldots,d$, and the different factors 
$b_i$ reflect the different initial amounts of sample mRNA, or different
overall reverse transcription, hybridization and detection efficiencies. 
The probe affinity $b_k$ contains factors that affect
all measurements with probe $k$ in the same manner, such as
sequence-specific labelling 
efficiency. The $b_k$ are assumed to be the same across all arrays.
There can be a non-zero overall offset $a_i$ for each color channel.
For a two-color cDNA array, $i=1,2$, and the $b_i$ take into account
the different overall efficiencies of the two dyes\footnote{% 
It has been reported that for some genes the dye bias is different from 
gene to gene, such that the proportionality factor does not simply factorize 
as in~(\ref{assumption.1}). As long as this only occurs sporadically, this 
should not have much effect on the estimation of the calibration and 
variance stabilization parameters. Further, by using an appropriate 
experimental design such as color-swap or reference design, the effects of 
gene-specific dye-biases to subsequent analyses can also be reduced.}.

\paragraph{Systematic effects associated with print-tip, PCR, or 
probe-sequence} 
Equation~\ref{assumption.1} can be generalized to
\begin{equation}\label{assumption.2} 
y_{ik}\approx a_{is} + b_{is} b_k c_{ik}.  
\end{equation} 
that is, the background term $a_{is}$ and the gain factor $b_{is}$ can
be different for different groups $s$ of probes on an array. For example,
with cDNA microarray data, it could be advantageous to fit different parameters 
for each print-tip group of spots, or for groups of spots whose DNA was 
PCR--amplified and stored in the same microtitre plate. For Affymetrix chips, 
one can find systematic dependences of the affinities $b_{is}$ or the 
background terms $a_{is}$ on the probe sequence.
This can be addressed by using the \Robject{strata} argument of 
the function \Robject{vsn}.

Situations in which the assumptions~(\ref{assumption.1}) or ~(\ref{assumption.2}) 
are violated include:

\paragraph{Saturation.} The biochemical reactions and/or the photodetection 
can be run in such a manner that saturation effects occur.
It may be possible to rescue such data by using non-linear transformations. 
Alternatively, it is recommended that the experimental parameters are 
chosen to avoid saturation.

\paragraph{Batch effects.} The probe affinities $b_k$ may differ between
different manufacturing batches of arrays due, e.g., to different
qualities of DNA amplification or printing. \Robject{vsn} cannot be
used to simultaneously calibrate and transform data from different
batches.

How to reliably diagnose and deal with such violations is beyond the scope 
of this vignette; see the references for more~\cite{Dudoit578,HSG2002}. 

\paragraph{Variance.} A further assumption that \Robject{vsn} makes is that 
the measurement error (more exactly: the variance) is the sum of two
contributions: an additive component that has roughly the same size
for all probes on an array, and a multiplicative component that is
roughly proportional in size to the signal's true value, with a
proportionality factor (called the \textit{coefficient of variation})
that is the same for all genes~\cite{RockeDurbin2001}.

\paragraph{Most genes unchanged assumption.} 
\Robject{vsn} assumes that only a minority (less than half) of genes on the
arrays is detectably differentially transcribed across the experiments. If it
is safe to assume that a smaller fraction of genes is non-negligibly
differentially transcribed, the efficiency of the estimation can be improved
by increasing the parameter \Robject{lts.quantile} from its default value
of 0.5 to a value between 0.5 and 1.

\paragraph{Processing biases.} 
Image analysis software for cDNA arrays typically estimates a
\textit{local background} associated with each probe intensity. For
Affymetrix arrays, the intensities from {mismatch} probes are thought
to represent the level of non-specific signal. In both cases, the raw
probe intensities may be \textit{adjusted} by subtracting these
background estimates. Some software packages, however, bias the
adjustment through rules based on the data values. For example,
Affymetrix' MAS 5.0 software uses the mismatch intensity only if it is
smaller than the probe's intensity, and otherwise employs a heuristic
to make sure that the net intensities always remain positive. As a
consequence, the intensities are systematically over-estimated, and
cannot be used with \Robject{vsn}. For Affymetrix data, we recommend
to use \Robject{vsn} on the probe intensities from the "CEL
file". For cDNA data, we recommend to use only background adjustment
procedures that estimate the background independent of the observed
foreground intensity.


\begin{thebibliography}{10}

\bibitem{HuberISMB2002}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Variance stablization applied to microarray data calibration and to
  quantification of differential expression.
\newblock \textit{Bioinformatics}, 18:S96--S104, 2002.

\bibitem{HSG2002}
W. Huber, A. von Heydebreck, and M. Vingron.
\newblock Analysis of microarray gene expression data.
\newblock \textit{Handbook of Statistical Genetics}, 
Eds.: D. J. Balding, M. Bishop, C. Cannings. 
John Wiley \& Sons, Inc. (2003).
\textit{(preprint available from author)}

\bibitem{HuberSAGMB2003}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Parameter estimation for the calibration and variance stabilization 
of microarray data.
\newblock \textit{Statistical Applications in Genetics and Molecular Biology}, 
Vol. 2: No. 1, Article 3, 2003. 
http://www.bepress.com/sagmb/vol2/iss1/art3

\bibitem{HuberWiley2004}
W. Huber, A. von Heydebreck, and M. Vingron.
\newblock Error models for microarray intensities.
\newblock \textit{Encyclopedia of Genomics, Proteomics and Bioinformatics}, 
John Wiley \& Sons, Inc. (2004).
\textit{(preprint available from author)}

\bibitem{RockeDurbin2001}
David~M. Rocke and Blythe Durbin.
\newblock A model for measurement error for gene expression analysis.
\newblock \textit{Journal of Computational Biology}, 8:557--569, 2001.

\bibitem{Dudoit578}
S. Dudoit, Y.~H. Yang, T.~P. Speed, and M.~J. Callow.
\newblock Statistical methods for identifying differentially expressed genes in
  replicated {cDNA} microarray experiments.
\newblock \textit{Statistica Sinica}, 12:111--139, 2002.

\bibitem{Alizadeh}
A.~A. Alizadeh et al.
\newblock Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling.
\newblock \textit{Nature}, 403:503--511, 2000.

\bibitem{Affycomp}
L.~M. Cope, R.~A. Irizarry, H.~A. Jaffee, Z.~Wu, and T.~P. Speed.
\newblock A Benchmark for Affymetrix GeneChip Expression Measures.
\newblock \textit{Bioinformatics}, 20:323--331, 2004.

\bibitem{RMA}
R.~A. Irizarry, B.~Hobbs, F.~Collin, Y.~D. Beazer-Barclay, K.~J. Antonellis, 
U.~Scherf, and T.~P. Speed. \newblock Exploration, normalization, and 
summaries of high density oligonucleotide array probe level data.
\newblock \textit{Biostatistics} 4:249--264, 2003.

\end{thebibliography}
\end{document}


