%\VignetteIndexEntry{Introduction to vsn}
%\VignetteDepends{vsn,affydata,hgu95av2cdf}
%\VignetteKeywords{Expression Analysis}
%\VignettePackage{vsn}

\documentclass[11pt,twocolumn]{article}
\usepackage[margin=2cm,nohead]{geometry}
\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\usepackage[%
baseurl={http://www.bioconductor.org},%
pdftitle={Introduction to robust calibration and variance stabilization with vsn},%
pdfauthor={Wolfgang Huber},%
pdfsubject={vsn},%
pdfkeywords={Bioconductor},%
pagebackref,bookmarks,colorlinks,linkcolor=darkblue,citecolor=darkblue,%
pagecolor=darkblue,raiselinks,plainpages,pdftex]{hyperref}

\SweaveOpts{keep.source=TRUE} 

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\arsinh}{\mathop{\mathgroup\symoperators arsinh}\nolimits}
\newcommand{\glog}{\mathop{\mathgroup\symoperators glog}\nolimits}
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{{\small\texttt{#1}}}

\newcommand{\myincfig}[3]{%
  \begin{figure}[t]
    \begin{center}
      \includegraphics[width=#2]{#1}
      \caption{\label{#1}#3}
    \end{center}
  \end{figure}
}

\setlength\columnsep{20pt}

\begin{document}
%----------------------------------------------------------------------------------------
\title{Introduction to robust calibration and variance stabilization with \Rpackage{vsn}}
\author{Wolfgang Huber}
%----------------------------------------------------------------------------------------
\maketitle
\tableofcontents

<<setup,echo=FALSE,results=hide>>=
options(width=41)
@ 

%------------------------------------------------------------
\section{Getting started}\label{sec:overv}
%------------------------------------------------------------ 
\Rpackage{vsn} is a method to preprocess microarray intensity data.
This can be as simple as
%
<<overv1, results=hide>>=
library("vsn")
data("kidney")
xnorm = justvsn(kidney)
@
%
where \Robject{kidney} is an \Rclass{ExpressionSet} object with
unnormalized data and \Robject{xnorm} the resulting
\Rclass{ExpressionSet} with calibrated and $\glog_2$-transformed
data.
%
<<overv2>>=
M = exprs(xnorm)[,1] - exprs(xnorm)[,2]
@
%
produces the vector of generalized log-ratios between the 
data in the first and second column.

\Rpackage{vsn} is a model-based method, and the more explicit way of 
doing the above task is \label{fit}
%
<<overv3, results=hide>>=
fit = vsn2(kidney)
ynorm = predict(fit, kidney)
@
<<overv4, echo=FALSE, results=hide>>=
stopifnot(identical(exprs(xnorm), exprs(ynorm)), identical(exprs(xnorm), exprs(fit)))
@ 
%
where \Robject{fit} is an object of class \Rclass{vsn} that contains
the fitted calibration and transformation parameters and the method
\Rfunction{predict} applies the fit to the data.
The two-step protocol is useful when you want to fit the parameters on a
subset of the data, e.\,g.\ a set some control or spike-in features,
and then apply the model to the complete set of data. Furthermore, it
allows further inspection of the \Robject{fit} object, e.\,g.\ for the
purposes of quality assessment.

Beside \Rclass{ExpressionSet}s, there are also \Rfunction{justvsn} 
methods for \Rclass{AffyBatch} objects from the \Rpackage{affy} package and
\Rclass{RGList} objects from the \Rpackage{limma} package. These are described 
in this vignette.

The so-called $\glog_2$ (short for \emph{generalized logarithm}) 
is a function that is like the logarithm (to base 2) for large values 
(large compared to the amplitude of the background noise),
but is less steep for smaller values.  Differences between the transformed
values are the \emph{generalized log-ratios}. These are 
shrinkage estimators of the logarithm of the fold change.
The usual \emph{log-ratio} is another example for an estimator\footnote{%
In statistics, the term \emph{estimator} is used to denote an algorithm
that calculates a value from a set of measured data. 
This value is intended to correspond to a parameter of the 
underlying distribution that generated the data. Depending on the amount of the 
available data and the quality of the estimator, the 
correspondence between the estimated value and the true value may be more 
or less faithful. For example, the arithmetic mean and the median are two 
different estimators of the expectation value of a distribution.}
of log fold change. 
There is also a close relationship between background correction of 
the intensities and the variance properties of these different estimators. Please
see Section~\ref{sec:shrink} for more explanation of these issues. 

How does \Rpackage{vsn} work? In short, each column is calibrated by
an affine transformation\footnote{It is possible to stratify the
transformations within columns, see the \Robject{strata} parameter of
\Rfunction{vsn}.}, then the whole data are transformed by a logarithm-like
variance-stabilizing transformation.  After this, systematic array- or
dye-biases should be removed, and the variance should be approximately
independent of the mean intensity.  Many statistical methods such as
hypothesis tests, ANOVA modeling, clustering, or classification work
better or are easier to use if the variance of the data is roughly the
same for all observations\footnote{Note that \Rpackage{vsn} only
addresses the dependence of the variance on the mean intensity. There
may be other factors influencing the variance, such as gene-inherent
properties, or changes of the tightness of transcriptional control in
different conditions.  If necessary, these need to be addressed by
other methods.}.

%------------------------------------------------------------
\section{Running vsn on data from a single two-color array} 
%------------------------------------------------------------
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-nkid-scp}  
\caption{\label{vsn-nkid-scp}%
Scatterplots of the kidney example data, which was obtained from a 
two-color cDNA array by quantitating spots and subtracting a local background 
estimate.
a) normalized and transformed with \Rpackage{vsn}, 
b) unnormalized and $\log_2$-transformed.
Panel a shows the data from the complete set of \Sexpr{nrow(kidney)} 
spots on the array, panel b only the \Sexpr{sum(0==rowSums(exprs(kidney)<=0))} 
spots for which both red and green net intensities were greater than 0. 
Those spots which are missing in panel b are colored in orange in panel a.}
\end{center}\end{figure*}
%
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-nkid-sdmean}  
\caption{\label{vsn-nkid-sdmean}%
Standard deviation versus rank of the mean, and the mean, respectively.}
\end{center}\end{figure*}
%
The dataset \Robject{kidney} contains
example data from a single cDNA array on which two biologically
similar samples, one labeled in green (Cy3), one in red (Cy5), were
hybridized.  The two columns of the matrix \Robject{exprs(kidney)}
contain the green and red intensities, respectively. A local 
background estimate\footnote{%
See Section~\ref{sec:shrink} for more on the relationship between 
background correction and variance stabilizing transformations.} 
was calculated by the image analysis software and subtracted, hence 
some of the intensities in \Robject{kidney} are close to zero or 
negative. In
Figure~\ref{vsn-nkid-scp} you can see the scatterplot of the
calibrated and transformed data. For comparison, the scatterplot of
the log-transformed raw intensities is also shown.
%
<<nkid-scp,include=FALSE,fig=TRUE,width=8,height=4.5>>=
par(mfrow=c(1,2))
select = (0==rowSums(exprs(kidney)<=0))
plot(exprs(xnorm), main = "a) vsn", 
  pch = ".", asp=1,
  col=ifelse(select, "black", "orange"))
plot(log2(exprs(kidney)[select, ]), 
  main = "b) raw", pch = ".", asp=1)
@
%

To verify the variance
stabilization, there is the function \Robject{meanSdPlot}. For each
probe $k=1,\ldots,n$ it shows the estimated standard deviation
$\hat{\sigma}_k$ on the $y$-axis versus the rank of the average
$\hat{\mu}_k$ on the $x$-axis,
\begin{equation}
\hat{\mu}_k     =\frac{1}{d}  \sum_{i=1}^d h_{ki}\quad\quad
\hat{\sigma}_k^2=\frac{1}{d-1}\sum_{i=1}^d (h_{ki}-\hat{\mu}_k)^2.
\end{equation}
<<nkid-sdmean,include=FALSE,fig=TRUE,width=8,height=4.5,results=hide>>=
par(mfrow=c(1,2))
meanSdPlot(xnorm, ranks=TRUE)
meanSdPlot(xnorm, ranks=FALSE)
@
%
Such a plot is shown in Figure~\ref{vsn-nkid-sdmean}.  The red dots,
connected by lines, show the running median of the standard
deviation\footnote{Window width: 10\%, window midpoints 5\%, 10\%,
15\%, \ldots.}. Within each window, the median may be considered a
pooled estimator of the standard deviation, and the curve given by the
red line is an estimate of the systematic dependence of the standard
deviation on the mean. After variance stabilization, this should be
approximately a horizontal line.  It may have some random
fluctuations, but should not show an overall trend.  If this is not
the case, that usually indicates a data quality problem, or is a
consequence of inadequate prior data preprocessing. 
The rank ordering distributes the data evenly
along the $x$-axis. A plot in which the $x$-axis shows the average
intensities themselves is obtained by calling the \Robject{plot}
command with the argument \Robject{ranks=FALSE}.

The histogram of the \Robject{M}-values is shown in 
Figure~\ref{vsn-nkid-histM}.
%
<<nkid-histM,include=FALSE,echo=FALSE,fig=TRUE,results=hide,width=4,height=4>>=
hist(M, breaks=50, col="#d95f0e")
@
\myincfig{vsn-nkid-histM}{0.45\textwidth}{Histogram of generalized 
log-ratios \Robject{M} for the kidney example data.}

%------------------------------------------------------------
\section{Running vsn on data from multiple arrays 
(``single color normalization'')} 
%------------------------------------------------------------
The package includes example data from a series of 8 cDNA arrays 
on which different lymphoma were hybridized together with a reference 
cDNA~\cite{Alizadeh}.
<<lymphoma>>=
data("lymphoma")
dim(lymphoma)
@
%
\begin{table}[t]
%\fbox{
\begin{minipage}{0.5\textwidth}
<<pDatalym>>=
pData(lymphoma)
@ 
\end{minipage}
%}
\caption{\label{tab:lymPD}%
The \Robject{phenoData} of the \Robject{lymphoma} dataset.}
\end{table}
%
The 16 columns of the \Robject{lymphoma} object contain the red and
green intensities, respectively, from the 8 slides, as shown in 
Table~\ref{tab:lymPD}. 
Thus, the CH1 intensities are in columns $1, 3, \ldots, 15$,
the CH2 intensities in columns $2, 4, \ldots, 16$.  We can call
\Robject{vsn} on all of them at once:
%
<<lym-sdmean1,results=hide>>=
lym = justvsn(lymphoma)
@
<<lym-sdmean2,include=FALSE,fig=TRUE>>=
meanSdPlot(lym)
@
\myincfig{vsn-lym-sdmean2}{0.45\textwidth}{Standard deviation 
versus rank of the mean for the lymphoma example data}
Again, Figure~\ref{vsn-lym-sdmean2} helps to visually verify that the
variance stabilization worked.  As above, we can obtain the
generalized log-ratios for each slide, by subtracting the common
reference intensities from those for the 8 samples:
%
<<lym-M,include=FALSE,fig=TRUE,width=8,height=4.5,results=hide>>=
iref = (1:8)*2-1
ismp = (1:8)*2
M = exprs(lym)[,ismp] - exprs(lym)[,iref] 
colnames(M) = lymphoma$sample[ismp]
A = rowMeans(exprs(lym))
par(mfrow=c(1,2))
plot(A, M[,"CLL-13"], pch=".")
abline(h=0, col="red")
plot(A, M[,"DLCL-0032"], pch=".")
abline(h=0, col="red")
@
%
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-lym-M}  
\caption{\label{vsn-lym-M}%
Mean-difference plots for two slides from the lymphoma example data.}
\end{center}\end{figure*}
%
Figure~\ref{vsn-lym-M} shows the resulting $M$-vs-$A$-plots~\cite{Dudoit578}
for two of the arrays. Note that in the left
scatterplot, there is a cloud of points at low intensities that is
concentrated slightly off the line $M=0$.  In the right scatterplot, a
similar cloud sits right on the $M=0$ line. This could be related to a
quality problem with the left slide (e.\,g. related to the PCR
amplification or the printing, see Section~\ref{sec.qc}).

%---------------------------------------------------------
\section{Running vsn on Affymetrix data} \label{affy}
%---------------------------------------------------------
The package \Rpackage{affy} provides excellent functionality for
reading and processing Affymetrix genechip data, and you are encouraged
to refer to the documentation of the package \Rpackage{affy} 
for more information about data structures and available methods. 
%
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-figaffy}  
\caption{\label{vsn-figaffy}%
Reults of \Rfunction{justvsn} and \Rfunction{rma} on the Dilution 
example data. Chip 1 was hybridized with 20 $\mu$g RNA from liver,
Chip 3 with 10 $\mu$g of the same RNA.}
\end{center}\end{figure*}

The preprocessing of Affymetrix genechip data involves
the following steps:
(i) background correction,
(ii) between-array calibration,
(iii) transformation and (iv) summarization.
The \Rfunction{vsn} method addresses steps (i)--(iii).
For the summarization, I recommend to use the RMA method~\cite{RMA},
and a simple wrapper that provides all of these is provided through 
the method \Rfunction{justvsn}.
%
<<affy1,results=hide>>=
library("affydata")
data("Dilution")
d.vsn = justvsn(Dilution)
@ 
For comparison, we also run \Rfunction{rma}.
<<affy2,results=hide>>=
d.rma = rma(Dilution)
@ 
%
The resulting scatterplots are shown and compared in Figure~\ref{vsn-figaffy}.
%
<<figaffy,include=FALSE,fig=TRUE,width=8,height=9>>=
par(mfrow=c(2,2), pch=".")
w = c(1,3)
titvsn = "vsn: chip 1 vs 3"
titrma = "rma: chip 1 vs 3"
plot(exprs(d.vsn)[,w], main=titvsn, asp=1)
plot(exprs(d.rma)[,w], main=titrma, asp=1)
plot(exprs(d.rma)[,1], exprs(d.vsn)[,1], 
  xlab="rma", ylab="vsn", asp=1, 
  main="chip 1: expression values")
abline(a=0, b=1, col="red")
plot(diff(t(exprs(d.rma)[,w])), 
     diff(t(exprs(d.vsn)[,w])), 
     xlab="rma", ylab="vsn", asp=1,
     main="M values chip 1 vs 3",
     xlim=c(-1,1), ylim=c(-1,1))
abline(a=0, b=1, col="red")
@

%---------------------------------------------------------
\section{Running vsn on \Robject{RGList} objects} \label{limma}
%---------------------------------------------------------
There is a \Rfunction{justvsn} method for \Rclass{RGList} objects.
%
<<limma, results=hide>>= 
library("limma")
wg = which(lymphoma$dye=="Cy3")
wr = which(lymphoma$dye=="Cy5")

lymRG = new("RGList", list(
  R=exprs(lymphoma)[, wr],
  G=exprs(lymphoma)[, wg]))

lymES = justvsn(lymRG)
@ 
%
The method combines the \Robject{R} and \Robject{G} slots of the
\Rclass{RGList} object into one matrix and calls the function
\Rfunction{vsnMatrix} on it. The return value is an
\Rclass{ExpressionSet}, shown in Table~\ref{tab:lymES}. 
%
\begin{table*}[t]
\begin{minipage}{\textwidth}
<<lymES>>=
lymES
@ 
\end{minipage}
\caption{\label{tab:lymES}%
The \Rclass{ExpressionSet} object \Robject{lymES}.}
\end{table*}
%
Note that the metadata of the resulting 
\Rclass{ExpressionSet} is minimal (due to the flexibility in the amount and 
quality of metadata that is in an \Rclass{RGList}), and that you will typically 
need to add the metadata to the \Rclass{ExpressionSet} afterwards. For this, we 
construct the \Rclass{AnnotatedDataFrame} object \Robject{adf} and assign it into 
the \Robject{phenoData} slot of \Robject{lymES}.
%
<<addmeta>>=
adf = new("AnnotatedDataFrame", 
 data=pData(lymphoma[,c(wr, wg)]),
 varMetadata=
   varMetadata(lymphoma[,c(wr,wg)]))
phenoData(lymES) = adf 
@ 
%
One further manipulation is necessary to ensure the internal consistency of 
the \Rclass{ExpressionSet} object:
%
<<sampleNames>>=
colnames(exprs(lymES)) = sampleNames(lymES)
@ 
%
Now we can use linear modeling tools from \Rpackage{limma} to find
differentially expressed genes.
Please take care of the ordering of the columns in the \Rclass{ExpressionSet}: 
first come all the red ones, then all the green ones.
%
<<lymM>>=
lymM = new("ExpressionSet",
 exprs=exprs(lymES)[,1:8]-exprs(lymES)[,9:16],
 phenoData=phenoData(lymES[,1:8]))
@
<<doublecheck, echo=FALSE>>=
stopifnot(ncol(lymES)==16L)
@ 
<<samp, print=TRUE>>=
sampleClass=factor(sub("-.*$", "", lymM$sample))
@ 
% 
\label{lmFit}
%
<<design>>=
design = model.matrix(~sampleClass)
lf=lmFit(lymM, 
   design[,"sampleClassDLCL", drop=FALSE])
lf=eBayes(lf)
@ 
%
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-figlimma}  
\caption{\label{vsn-figlimma}%
Left: histogramme of $p$-values from the moderated $t$-test between the 
\Sexpr{levels(sampleClass)[1]} and
\Sexpr{levels(sampleClass)[2]} groups on the \Robject{lymM} values.
Right: $M$-values for the 5 genes with the smallest $p$-values.}
\end{center}\end{figure*}
%
<<figlimma,fig=TRUE,include=FALSE,width=8,height=4.5>>=
par(mfrow=c(1,2))
hist(lf$p.value, 100, col="orange") 
matplot(t(exprs(lymM)[order(lf$p.value)[1:5],]), 
  lty=1, type="l", pch=16, 
  col=hsv(seq(0,1,length=5), 1, 0.6), 
  ylab="M", xlab="arrays")
@ 
%
%--------------------------------------------------
\subsection{Background subtraction}
%--------------------------------------------------
Many image analysis programs for microarrays provide local background
estimates, which are typically calculated from the fluorescence signal
outside, but next to the features. These are not always useful. Just
as any measurement, these local background estimates are also subject
to random measurement error, and subtracting them from the foreground
intensities will lead to increased random noise in the signal. On the
other hand side, doing so may remove systematic artifactual drifts in the
data, for example, a spatial gradient. This is a typical example of the
variance--bias trade-off, or \emph{accuracy}--\emph{precision}
trade-off. 

So what is the optimal analysis strategy, should you subtract local
background estimates or not? The answer depends on the properties of
your particular data. \Rpackage{vsn} itself estimates and subtracts an
over-all background estimate (per array and colour, see
Section~\ref{sec:calib}), so an additional local background correction
is only useful if there actually is local variability across an array,
for example, a spatial gradient.

Supposing that you have decided to subtract the local background
estimates, how is it done? 
When called with the argument \Robject{backgroundsubtract=TRUE}\footnote{%
Note that the default value for this parameter is \Robject{FALSE}.}, 
the \Rfunction{justvsn} method will subtract local background estimates in
the \Robject{Rb} and \Robject{Gb} slots of the incoming \Rclass{RGList}.
To demonstrate this, we construct an \Rclass{RGList} object \Robject{lymRGwbg}.
%
<<makebg>>=
rndbg=function(x, off, fac)
 array(off+fac*runif(prod(dim(x))),
       dim=dim(x))

lymRGwbg    = lymRG
lymRGwbg$Rb = rndbg(lymRG, 100, 30)
lymRGwbg$Gb = rndbg(lymRG,  50, 20)
@ 
%
In practice, of course, these values will be read from the image
quantitation file with a function such as \Rfunction{read.maimages}
that produces the \Rclass{RGList} object. We can call
\Rfunction{justvsn} on it
%
<<justvsnwbg, results=hide>>=
lymESwbg = justvsn(lymRGwbg[, 1:3], 
   backgroundsubtract=TRUE)
@ 
%
(Here we only do it for the first 3 arrays to save compute time.)

%--------------------------------------------------
\subsection{Print-tip groups}
%--------------------------------------------------
\begin{figure}[t]\begin{center}
\includegraphics[width=0.45\textwidth]{vsn-figstrata}  
\caption{\label{vsn-figstrata}%
Scatterplot of normalized and transformed intensities for 
the red channel of array 1. Values on the $x$-axis correspond 
to normalization without strata (\Robject{lymES}), 
values on the $y$-axis to normalization with strata (\Robject{lymESstr}).
\end{center}\end{figure}
%
By default, \Rpackage{vsn} computes one normalization transformation
with a common set of parameters for all features of an array (and
colour, if it is a multi-color microarray), see
Section~\ref{sec:calib}.  Sometimes, there is a need for
stratification by further variables of the array manufacturing
process, for example, print-tip groups (sectors) or microtitre
plates. This can be done with the \Robject{strata} parameter of
\Rfunction{vsn2}.

The example data that comes with the package does not directly provide
the information which print-tip each feature was spotted with, but we
can write a little function \Rfunction{pinId} that reconstructs this information,
%
<<pinId>>=
gridrows = 4
gridcols = 4
spotrows = 24
spotcols = 24
pinId = rep(seq_len(gridrows*gridcols), 
   each=spotrows*spotcols)
@
%
and call
%
<<strata>>=
EconStr = justvsn(lymRG[,1:2], strata=pinId)
@
%
To save CPU time, we only call this on the first two arrays. We compare the 
result to calling \Rfunction{justvsn} without \Robject{strata},
%
<<nostrata>>=
EsenzaStr = justvsn(lymRG[,1:2])
@
%
A scatterplot of the comparison is shown in Figure~\ref{vsn-figstrata}.
%
<<figstrata,fig=TRUE,include=FALSE,width=4,height=4.5>>=
j=1L
plot(exprs(EsenzaStr)[,j], exprs(EconStr)[,j], 
  pch=".", asp=1, 
  col=hsv(seq(0,1,length=max(pinId)), 1, 0.6)[pinId], 
  xlab="without strata", 
  ylab="print-tip strata",
  main=sampleNames(lymES)[j])
@
%
%---------------------------------------------------------------------
\section{Missing values} \label{sec:miss}
%---------------------------------------------------------------------
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-figmiss}  
\caption{\label{vsn-figmiss}%
Scatterplot of normalized and transformed intensities for 
the red channel of array 1. Values on the $x$-axis correspond 
to normalization without strata (\Robject{lymES}), 
values on the $y$-axis to normalization with strata (\Robject{lymESstr}).
\end{center}\end{figure}
%
The parameter estimation algorithm of \Rpackage{vsn} is able to deal with
missing values in the input data. To demonstrate this, we generate an 
\Rclass{ExpressionSet} \Robject{lym2} in which about 10\% of all intensities 
are missing,
%
<<miss1>>=
lym2 = lymphoma
exprs(lym2)[sample(prod(dim(lym2)), 16000)] = NA
table(is.na(exprs(lym2)))
@ 
and call \Rfunction{vsn2} on it.
<<miss2>>=
fit1 = vsn2(lymphoma)
fit2 = vsn2(lym2)
@ 
%
The resulting fitted parameters are not identical, but very similar. 
See Figure~\ref{vsn-figmiss}.
%
<<figmiss,fig=TRUE,include=FALSE,width=8,height=4.5>>=
par(mfrow=c(1,2))
for(j in 1:2){
  p1 = fit1@par[,,j]
  p2 = fit2@par[,,j]
  d  = max(abs(p1-p2))
  stopifnot(d<0.05)
  plot(p1, p2, pch=16, asp=1,
    main=paste("d", signif(d,3), sep="="))
  abline(a=0, b=1, col="blue")
}
@ 

%---------------------------------------------------------------------
\section{Normalization against an existing reference dataset} \label{sec:ref}
%---------------------------------------------------------------------
Up to here, we have considered the joint normalization of a set of arrays to each
other. What happens if, after analysing a set of arrays in this
fashion, we obtain some additonal arrays? Do we re-run the
whole normalization again for the complete, new and bigger set of
arrays? This may sometimes be impractical. 

Imagine we have used a set of training arrays for setting up a
classifier that is able to discriminate different biological states of
the samples based on their mRNA profile. Now we get new test
arrays to which we want to apply the classifier. Clearly, we do not
want to re-run the normalization for the whole, new and bigger dataset, as this
would change the training data; neither, we can normalize only the
test arrays between themselves, without normalizing them ``towards''
the reference training dataset. What we need is a normalization
procedure that normalizes the new test arrays ``towards'' the existing
reference dataset without changing the latter.

% 
To simulate this situation, we pretend that the Cy5 channels of the 
\Robject{lymphoma} dataset can be treated as 8
single-colour arrays, and fit a model to the first 7.
%
<<ref1>>=
ref = vsn2(lymphoma[, ismp[1:7]])
@ 
Now we call \Rfunction{vsn2} on the 8-th array, with the output
from the previous call as the reference.
%
<<ref2>>=
f8 = vsn2(lymphoma[, ismp[8]])
@
%
We can compare to what we would have gotten if we had fitted the model 
to all 8 arrays:
%
<<ref3>>=
fall = vsn2(lymphoma[, ismp])
f8@par[,1,]
fall@par[,8,]
@
%
<<hiddenchecks,echo=FALSE>>=
stopifnot(length(ismp)==8L, max(abs(f8@par[,1,]-fall@par[,8,]))<0.05)
@ 

More details on this can be found in the vignettes
\emph{Verifying and assessing the performance with simulated data} 
and
\emph{Likelihood Calculations for vsn}
that come with this package.

%---------------------------------------------------------------------
\section{The calibration parameters} \label{sec:calib}
%---------------------------------------------------------------------
If $y_{ki}$ is the matrix of uncalibrated data, with $k$ indexing the
rows and $i$ the columns, then the calibrated data $y_{ki}'$ is
obtained through scaling by $\lambda_{si}$ and shifting by $o_{si}$:
\begin{equation}\label{eq.cal}
y_{ki}' = \frac {y_{ki}-o_{si}}{\lambda_{si}},
\end{equation}
where $s\equiv s(k)$ is the so-called \textit{stratum} for probe $k$. In the
simplest case, there is only one stratum, i.\,e.\ the index $s$ is always
equal to 1, or may be omitted altogether. This amounts to assuming that 
that the data of all probes on an array were subject to the same 
systematic effects, such that an array-wide calibration is sufficient.

A model with multiple strata per array may be useful for spotted
arrays. For these, stratification may be according to
print-tip~\cite{Dudoit578} or PCR-plate~\cite{HSG2002}. For
oligonucleotide arrays, it may be useful to stratify the probes by
physico-chemical properties, e.\,g.\, to assume that probes of
different sequence composition attract systematically different levels
of unspecific background signal.

The transformation to a scale where the variance of the data is approximately
independent of the mean is 
\begin{eqnarray}
h_{ki} &=& \arsinh(a_0+b_0y_{ki}') \label{eq.vs} \\
  &=& \log\left(a_0+b_0y_{ki}'+\sqrt{\left(a_0+b_0y_{ki}'\right)^2+1}\right).
\end{equation}
Equations~(\ref{eq.cal}) and (\ref{eq.vs}) can be combined, so that the whole 
transformation is given by 
\begin{equation}\label{eq.transf}
h_{ki} = \arsinh(a_{si} + b_{si} y_{ki}). 
\end{equation}
Here, $a_{si}=a_0-b_0o_{si}/\lambda_{si}$ and $b_{si}=b_0/\lambda_{si}$ 
are the combined calibation and transformation parameters for probes from
stratum $s$ and sample $i$.

We can access the calibration and transformation parameters through
<<nkid-calib1>>=
fit@par
@
% 
For a dataset with $d$ samples and $s$ strata,
\Robject{fit@par} is a numeric array with dimensions $(s, d, 2)$. 
For the example data that was used in Section~\ref{sec:overv} to generate 
\Robject{fit}, $d=2$ and $s=1$.
\Robject{fit@par[s, i, 1]}, the first line in the results of the above code chunk, 
is what was called $a_{si}$ in Eqn.~(\ref{eq.transf}), and
\Robject{fit@par[s, i, 2]}, the second line, is $b_{si}$. 

%---------------------------------------------------------------------
\subsection{More on calibration} 
%---------------------------------------------------------------------
\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-nkid-calib4}  
\caption{\label{vsn-nkid-calib4}%
Scatterplots for badly biased data. 
Left hand side: raw data on log-log scale, 
right hand side: after calibration and transformation with vsn.}
\end{center*}\end{figure}
%
Now suppose the kidney example data were not that well measured, and 
the red channel had a baseline that was shifted by 500 and a scale 
that differed by a factor of $0.25$:
%
<<nkid-calib2>>=
bkid = kidney
exprs(bkid)[,1] = 0.25*(500+exprs(bkid)[,1])
@
%
We can again call \Rfunction{vsn2} on these data
%
<<nkid-calib3,results=hide>>=
bfit <- vsn2(bkid)
@
% 
<<nkid-calib-warn1,echo=FALSE,results=hide>>=
oldwarn <- options(warn=-1)
@
%
<<nkid-calib4,fig=TRUE,include=FALSE,width=8,height=4.5>>=
par(mfrow=c(1,2))
plot(exprs(bkid), main="raw", 
     pch=".", log="xy")
plot(exprs(bfit), main="vsn", 
     pch=".")
bfit@par[1,,]
@
% 
<<nkid-calib-warn2,echo=FALSE,results=hide>>=
options(oldwarn)
rm(oldwarn)
@
%
The factor for the red channel is now about four times as large as
before.  The result is shown in Figure~\ref{vsn-nkid-calib4}.

%-------------------------------------------------------------------
\section{Assessing vsn and comparing it to other methods}
%-------------------------------------------------------------------
\Rpackage{vsn} is a parameter estimation algorithm that fits the
parameters for a certain model. In order to see how good the estimator
is, we can look at bias, variance, sample size dependence, robustness
against model misspecificaton and outliers. This is done in the
vignette \emph{Verifying and assessing the performance with simulated
data} that also comes with this package.

Practically, the more interesting question is how different microarray
calibration and data transformation methods compare to each other. For this,
one needs to specify a measure of goodness. One approach is to compare the
obtained values against a known truth. This can be done in controlled spike-in
experiments and in dilution series, which allow to systematically assess the
performance of the methods at different biologically relevant spike-in
concentrations. Like any statistical method, one can make different choices
with respect to the trade-off between bias and variance~\cite{Affycomp}.

Here, we focus on one particular aspect: the overall sensitivity and
specificity in detecting differential transcription. The following
type of analysis can be applied to any data set that contains
replicated measurements made on samples from biologically distinct,
known groups. The idea is that we compare the within-group variability
(among the biological replicates) to the between-group variability
(between different tissue types). The smaller the former and the
larger the latter, the better we may deem the performance of the
calibration and data transformation.

\begin{figure*}[t]\begin{center}
\includegraphics[width=0.9\textwidth]{vsn-comp}
\caption{\label{fig-comp}Left hand side: $x$-axis -- generalized
log-ratios for slide 1 from \Robject{vsn}, $y$-axis -- log-ratios
for slide 1 after global median normalization. For most genes, the two
are the same, but in some cases the generalized log-ratio is smaller.
It is never larger. This demonstrates the \textit{ratio shrinkage} by
the variance stabilization. Right hand side: quantile-quantile-plot of
the $t$-statistic for the comparison between the 4 slides with CLL and
the 4 with DLCL. The $t$-statistics from \Robject{vsn} are larger,
i.\,e.\ it compares more favorable with respect to the relative size
of between- and within-group variability.}
\end{center}\end{figure*}

Here, as a measure of the relative size of between- and within-group
variability we take the size of the $t$-statistics.  The acceptable
use of CPU time and disk memory of a package vignette is limited, thus
here we stick to a very simple-minded calculation and a small data
set. See Figure~\ref{fig-comp} and the calculations below. Two
applications to larger data sets are described in
reference~\cite{HuberISMB2002}.  More sophisticated analyses can be
made by comparing not just the distributions of $t$-statistics, but
for example, the estimated false discovery rates, using different test
statistics. You are encouraged to try this out with your own data.
%

First, we normalize the lymphoma data using the \Rfunction{loess} 
normalization,
%
<<loess,results=hide>>=
lymMls=new("ExpressionSet", exprs=
   normalizeWithinArrays(lymRG, method="loess")$M)
@ 
% 
then we calculate differential expression statistics just as above
on page~\pageref{lmFit}.
%
<<lmFitagain>>=
lfls = eBayes(lmFit(lymMls, 
   design[,"sampleClassDLCL", drop=FALSE]))
@ 
%
<<comp,results=hide,fig=TRUE,width=8,height=4.5,include=FALSE>>=
par(mfrow=c(1,2))
plot(exprs(lymM)[,j], exprs(lymMls)[,j], 
  main=sampleNames(lymM)[j], pch=".", asp=1)
abline(a=0,b=1,col="blue")
qqplot(lf$t, lfls$t, 
  xlab="t (vsn)", ylab="t (loess)", 
  main="QQ plot", pch=".")
abline(a=0,b=1,col="blue")
@

%------------------------------------------------------------
\section{vsn, shrinkage and background correction} \label{sec:shrink}
%------------------------------------------------------------
%
<<calcshrink, echo=FALSE, results=hide>>=
fc = 0.5
x2 = seq(0.5, 15, by=0.5)
x1 = x2/fc
m = s = numeric(length(x1))
n  = 20000
sa = 1
b  = 1
sb = 0.1
sdeta = 0.1
for(i in 1:length(x1)){
  z1 = sa*rnorm(n)+x1[i]*b*exp(sb*rnorm(n))
  z2 = sa*rnorm(n)+x2[i]*b*exp(sb*rnorm(n))
  if(i%%2==1) {
    q = log(z1/z2)
    m[i] = mean(q, na.rm=TRUE)
    s[i] = sd(q, na.rm=TRUE)
  } else {
    h = (asinh(z1/(sa*b/sb))-asinh(z2/(sa*b/sb)))
    m[i] = mean(h)
    s[i] = sd(h)
  }
}

colq = c("black", "blue")
lty  = 1
pch  = c(20,18)
cex  = 1.4
lwd  = 2
@ 
%
<<figshrink, fig=TRUE, echo=FALSE, include=FALSE, width=4, height=4.5>>=
mai=par("mai"); mai[3]=0; par(mai)
plot(x2, m, ylim=c(-1.2,2), type="n", xlab=expression(x[2]), ylab="")
abline(h=-log(fc), col="red", lwd=lwd, lty=1)
abline(h=0, col="black", lwd=1, lty=2)
points(x2, m, pch=pch, col=colq, cex=cex)
segments(x2, m-2*s, x2, m+2*s, lwd=lwd, col=colq, lty=lty)
legend(8.75, -0.1, c("q","h"), col=colq, pch=pch, lty=lty, lwd=lwd)
@
%
\myincfig{vsn-figshrink}{0.45\textwidth}{%
The shrinkage property of the generalized log-ratio.  
Blue diamonds and error bars correspond to mean and standard
deviation of the generalized log-ratio $h$, as obtained from \Rpackage{vsn}, 
black dots and error bars to the naive log-ratio $q$.  
For this figure, data were simulated generated from the 
additive-multiplicative error model~\cite{RockeDurbin2001,HuberSAGMB2003,HuberWiley2004}.
The horizontal line corresponds to the true log-ratio $\log(2)\approx0.693$.
For intensities $x_2$ that are larger than about ten times the additive noise 
level $\sigma_a$, generalized log-ratio $h$ and naive log-ratio $q$ coincide. 
For smaller intensities, we can see a \textit{variance-bias trade-off}: 
$q$ has no bias but a huge variance, thus an estimate of the 
fold change based on a limited set of data can be arbitrarily off.
In contrast, $h$ keeps a constant variance -- for the 
price of systematically underestimating the true fold change.}

Generalized log-ratios can be viewed as a \textit{shrinkage estimator}: they
are always smaller than or equal to the naive log-ratios; equality is
asymptotically reached if the probe intensities are large both for samples $i$
and $j$. Their advantage is that they do not suffer from the variance
divergence of the naive log-ratios at small intensities: they remain
well-defined and statistically meaningful when the data come close to zero or
even become negative.  Please consult the references for more on the
mathematical-methodical background~\cite{HuberISMB2002,HSG2002,HuberSAGMB2003}.



%---------------------------------------------------------
\section{Quality assessment}\label{sec.qc}
%---------------------------------------------------------
\Robject{vsn} makes some assumptions about your data that need to
hold if it is to produce meaningful results. We have found them
appropriate for many microarray experiments, but it is your
responsibility to make sure that they hold for your data.

First, \Robject{vsn} assumes that the measured signal $y_{ik}$
increases, to sufficient approximation, proportionally to the mRNA
abundance $c_{ik}$ of gene $k$ on the $i$-th array, or on the $i$-th
color channel:
\begin{equation}\label{assumption.1} 
y_{ik}\approx a_i + b_i b_k c_{ik}.  
\end{equation} 
For a series of $d$ single-color arrays such as Affymetrix arrays
or cDNA nylon membranes, $i=1,\ldots,d$, and the different factors 
$b_i$ reflect the different initial amounts of sample mRNA, or different
overall reverse transcription, hybridization and detection efficiencies. 
The probe affinity $b_k$ contains factors that affect
all measurements with probe $k$ in the same manner, such as
sequence-specific labelling 
efficiency. The $b_k$ are assumed to be the same across all arrays.
There can be a non-zero overall offset $a_i$ for each color channel.
For a two-color cDNA array, $i=1,2$, and the $b_i$ take into account
the different overall efficiencies of the two dyes\footnote{% 
It has been reported that for some genes the dye bias is different from 
gene to gene, such that the proportionality factor does not simply factorize 
as in~(\ref{assumption.1}). As long as this only occurs sporadically, this 
should not have much effect on the estimation of the calibration and 
variance stabilization parameters. Further, by using an appropriate 
experimental design such as color-swap or reference design, the effects of 
gene-specific dye-biases to subsequent analyses can also be reduced.}.

\paragraph{Systematic effects associated with print-tip, PCR, or 
probe-sequence} 
Equation~\ref{assumption.1} can be generalized to
\begin{equation}\label{assumption.2} 
y_{ik}\approx a_{is} + b_{is} b_k c_{ik}.  
\end{equation} 
that is, the background term $a_{is}$ and the gain factor $b_{is}$ can
be different for different groups $s$ of probes on an array. For example,
with cDNA microarray data, it could be advantageous to fit different parameters 
for each print-tip group of spots, or for groups of spots whose DNA was 
PCR--amplified and stored in the same microtitre plate. For Affymetrix chips, 
one can find systematic dependences of the affinities $b_{is}$ or the 
background terms $a_{is}$ on the probe sequence.
This can be addressed by using the \Robject{strata} argument of 
the function \Robject{vsn}.

Situations in which the assumptions~(\ref{assumption.1}) or ~(\ref{assumption.2}) 
are violated include:

\paragraph{Saturation.} The biochemical reactions and/or the photodetection 
can be run in such a manner that saturation effects occur.
It may be possible to rescue such data by using non-linear transformations. 
Alternatively, it is recommended that the experimental parameters are 
chosen to avoid saturation.

\paragraph{Batch effects.} The probe affinities $b_k$ may differ between
different manufacturing batches of arrays due, e.g., to different
qualities of DNA amplification or printing. \Robject{vsn} cannot be
used to simultaneously calibrate and transform data from different
batches.

How to reliably diagnose and deal with such violations is beyond the scope 
of this vignette; see the references for more~\cite{Dudoit578,HSG2002}. 

\paragraph{Variance.} A further assumption that \Robject{vsn} makes is that 
the measurement error (more exactly: the variance) is the sum of two
contributions: an additive component that has roughly the same size
for all probes on an array, and a multiplicative component that is
roughly proportional in size to the signal's true value, with a
proportionality factor (called the \textit{coefficient of variation})
that is the same for all genes~\cite{RockeDurbin2001}.

\paragraph{Most genes unchanged assumption.} 
\Robject{vsn} assumes that only a minority (less than half) of genes on the
arrays is detectably differentially transcribed across the experiments. If it
is safe to assume that a smaller fraction of genes is non-negligibly
differentially transcribed, the efficiency of the estimation can be improved
by increasing the parameter \Robject{lts.quantile} from its default value
of 0.5 to a value between 0.5 and 1.

\paragraph{Processing biases.} 
Image analysis software for cDNA arrays typically estimates a
\textit{local background} associated with each probe intensity. For
Affymetrix arrays, the intensities from {mismatch} probes are thought
to represent the level of non-specific signal. In both cases, the raw
probe intensities may be \textit{adjusted} by subtracting these
background estimates. Some software packages, however, bias the
adjustment through rules based on the data values. For example,
Affymetrix' MAS 5.0 software uses the mismatch intensity only if it is
smaller than the probe's intensity, and otherwise employs a heuristic
to make sure that the net intensities always remain positive. As a
consequence, the intensities are systematically over-estimated, and
cannot be used with \Robject{vsn}. For Affymetrix data, we recommend
to use \Robject{vsn} on the probe intensities from the "CEL
file". For cDNA data, we recommend to use only background adjustment
procedures that estimate the background independent of the observed
foreground intensity.


\begin{thebibliography}{10}

\bibitem{HuberISMB2002}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Variance stablization applied to microarray data calibration and to
  quantification of differential expression.
\newblock \textit{Bioinformatics}, 18:S96--S104, 2002.

\bibitem{HSG2002}
W. Huber, A. von Heydebreck, and M. Vingron.
\newblock Analysis of microarray gene expression data.
\newblock \textit{Handbook of Statistical Genetics}, 
Eds.: D. J. Balding, M. Bishop, C. Cannings. 
John Wiley \& Sons, Inc. (2003).
\textit{(preprint available from author)}

\bibitem{HuberSAGMB2003}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Parameter estimation for the calibration and variance stabilization 
of microarray data.
\newblock \textit{Statistical Applications in Genetics and Molecular Biology}, 
Vol. 2: No. 1, Article 3, 2003. 
http://www.bepress.com/sagmb/vol2/iss1/art3

\bibitem{HuberWiley2004}
W. Huber, A. von Heydebreck, and M. Vingron.
\newblock Error models for microarray intensities.
\newblock \textit{Encyclopedia of Genomics, Proteomics and Bioinformatics}, 
John Wiley \& Sons, Inc. (2004).
\textit{(preprint available from author)}

\bibitem{RockeDurbin2001}
David~M. Rocke and Blythe Durbin.
\newblock A model for measurement error for gene expression analysis.
\newblock \textit{Journal of Computational Biology}, 8:557--569, 2001.

\bibitem{Dudoit578}
S. Dudoit, Y.~H. Yang, T.~P. Speed, and M.~J. Callow.
\newblock Statistical methods for identifying differentially expressed genes in
  replicated {cDNA} microarray experiments.
\newblock \textit{Statistica Sinica}, 12:111--139, 2002.

\bibitem{Alizadeh}
A.~A. Alizadeh et al.
\newblock Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling.
\newblock \textit{Nature}, 403:503--511, 2000.

\bibitem{Affycomp}
L.~M. Cope, R.~A. Irizarry, H.~A. Jaffee, Z.~Wu, and T.~P. Speed.
\newblock A Benchmark for Affymetrix GeneChip Expression Measures.
\newblock \textit{Bioinformatics}, 20:323--331, 2004.

\bibitem{RMA}
R.~A. Irizarry, B.~Hobbs, F.~Collin, Y.~D. Beazer-Barclay, K.~J. Antonellis, 
U.~Scherf, and T.~P. Speed. \newblock Exploration, normalization, and 
summaries of high density oligonucleotide array probe level data.
\newblock \textit{Biostatistics} 4:249--264, 2003.

\end{thebibliography}
\end{document}


