%\VignetteIndexEntry{vsn - introduction}
%\VignetteDepends{Biobase,vsn,affy,affydata,marray,multtest,limma,hgu95av2cdf}
%\VignetteKeywords{Expression Analysis}
%\VignettePackage{vsn}

\documentclass[11pt]{article}
\usepackage{geometry}\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\usepackage[%
baseurl={http://www.bioconductor.org},%
pdftitle={Robust calibration and variance stabilization with VSN},%
pdfauthor={Wolfgang Huber},%
pdfsubject={vsn},%
pdfkeywords={Bioconductor},%
pagebackref,bookmarks,colorlinks,linkcolor=darkblue,citecolor=darkblue,%
pagecolor=darkblue,raiselinks,plainpages,pdftex]{hyperref}

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\arsinh}{\mathop{\mathgroup\symoperators arsinh}\nolimits}
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{{\small\texttt{#1}}}

\newcommand{\myincfig}[3]{%
  \begin{figure}[htbp]
    \begin{center}
      \includegraphics[width=#2]{#1}
      \caption{\label{#1}#3}
    \end{center}
  \end{figure}
}

\begin{document}

%------------------------------------------------------------
\title{Robust calibration and variance stabilization with VSN}
%------------------------------------------------------------
\author{Wolfgang Huber}
\maketitle
\tableofcontents

<<no.nonsense,eval=FALSE,echo=FALSE,results=hide>>=
q(save="no")
@

<<setup,echo=FALSE,results=hide>>=
library("affy")
library("marray")
library("multtest")
library("limma")
oldopt <- options(digits=3)
on.exit( {options(oldopt)} )
@ 

%------------------------------------------------------------
\section{Getting started: brief overview}
%------------------------------------------------------------ 
\Rpackage{vsn} is a method to preprocess microarray intensity data.
Calling \Rpackage{vsn} can be as simple as

<<dummyex1,eval=FALSE>>=
e2 <- vsn(e1)
@

where \Robject{e1} is an \Robject{exprSet} with raw data and
\Robject{e2} one with calibrated and \textit{glog}-transformed data.
\Robject{e1} can also be a matrix, a data frame with numeric columns only,
or an object of class \Rclass{marrayRaw}. It contains the raw intensity
measurements from the DNA probes on a series of microarrays (with rows
corresponding to probes, columns to arrays and/or dyes).

The so-called \textit{glog} (short for 
\textit{\textbf{generalized logarithm}}) is a function that is like the
natural logarithm for large values (large compared to the background noise),
but is less steep for smaller values.  Differences between the transformed
values are the \textit{\textbf{generalized log-ratios}}. These are 
\emph{shrinkage estimators} of the natural logarithm of the fold change. 
For example,

<<dummyex2,eval=FALSE>>=
M <- exprs(e2)[,i] - exprs(e2)[,j]
@

produces the vector of generalized log-ratios between samples $i$ and
$j$. Notes that these are to base \textit{e}. If you want to convert them to
base 2, divide them by log(2). If you want to know the estimated the fold
change, exponentiate:

<<dummyex3,eval=FALSE>>=
M.base2 <- M/log(2)
fold.change <- exp(M)
@

Generalized log-ratios can be viewed as a \textit{shrinkage estimator}: they
are always smaller than or equal to the naive log-ratios; equality is
asymptotically reached if the probe intensities are large both for samples $i$
and $j$. Their advantage is that they do not suffer from the variance
divergence of the naive log-ratios at small intensities: they remain
well-defined and statistically meaningful when the data come close to zero or
even become negative.  Please consult the references for more on the
mathematical-methodical background
~\cite{HuberISMB2002,HSG2002,HuberSAGMB2003}.


In short, each column is calibrated by an affine transformation\footnote{It is
possible to stratify the transformations within columns, see the \Robject{strata}
parameter of \Rfunction{vsn}.}, then the whole data are transformed by a
variance-stabilizing transformation.  After this, systematic array- or
dye-biases should be removed, and the variance should be approximately
independent of the mean intensity.  Many statistical methods such as
hypothesis tests, ANOVA modeling, clustering, or classification work better or
are easier to use if the variance of the data is roughly the same for all
observations\footnote{Note that \Rpackage{vsn} only addresses the dependence
of the variance on the mean intensity. There may be other factors influencing
the variance, such as gene-inherent properties, or changes of the tightness of
transcriptional control in different conditions.  If necessary, these need to
be addressed by other methods.}.

%------------------------------------------------------------
\section{Running vsn on data from a single two-color array} 
%------------------------------------------------------------
The package includes example data from a cDNA array on which two
biologically very similar samples, one labeled in green (Cy3), one
in red (Cy5), were hybridized.
<<lib,results=hide>>= 
library("vsn") 
data("kidney") 
@ 
The two columns of the matrix \Robject{exprs(kidney)} contain the
green and red intensities, respectively. Let's try out \Robject{vsn} on
these example data. In Fig.~\ref{vsn-nkid-scp} you can see the
scatterplot of the calibrated and transformed data. For comparison,
the scatterplot of the log-transformed raw intensities is also shown.
<<nkid-calc, results=hide>>=
nkid <- vsn(kidney)
@
<<nkid-scp,include=FALSE,fig=TRUE,width=8,height=4>>=
par(mfrow=c(1,2))
log.na = function(x) log(ifelse(x>0, x, NA))
plot(exprs(nkid), main = "vsn", pch = ".")
plot(log.na(exprs(kidney)), main = "raw", pch = ".")
@
\myincfig{vsn-nkid-scp}{\textwidth}{Scatterplots of the kidney example
data}
\Robject{vsn} returns the transformed intensities in an object of
class \Rclass{exprSet}. Its slot \Robject{exprs} is a matrix of the
same size as the input data.  The plot in Fig.~\ref{vsn-nkid-scp}
shows the complete set of $n=9216$ red and green intensities, without
any thresholding or masking of data points.  To verify the variance
stabilization, there is the function \Robject{meanSdPlot}. For each
probe $k=1,\ldots,n$ it shows the estimated standard deviation
$\hat{\sigma}_k$ on the $y$-axis versus the rank of the average
$\hat{\mu}_k$ on the $x$-axis,
\begin{equation}
\hat{\mu}_k     =\frac{1}{d}  \sum_{i=1}^d h_{ki}\quad\quad
\hat{\sigma}_k^2=\frac{1}{d-1}\sum_{i=1}^d (h_{ki}-\hat{\mu}_k)^2.
\end{equation}
<<nkid-sdmean,include=FALSE,fig=TRUE,width=8,height=4,results=hide>>=
par(mfrow=c(1,2))
meanSdPlot(nkid, ranks=TRUE)
meanSdPlot(nkid, ranks=FALSE)
@
\myincfig{vsn-nkid-sdmean}{\textwidth}{Standard deviation versus rank
of the mean, and the mean, respectively}
Such a plot is shown in Fig.~\ref{vsn-nkid-sdmean}.  The red dots,
connected by lines, show the running median of the standard
deviation\footnote{Window width: 10\%, window midpoints 5\%, 10\%,
15\%, \ldots.}. Within each window, the median may be considered a
pooled estimator of the standard deviation, and the curve given by the
red line is an estimate of the systematic dependence of the standard
deviation on the mean. After variance stabilization, this should be
approximately a horizontal line.  It may have some random
fluctuations, but should not show an overall trend.  If this is not
the case, that usually indicates a data quality problem, or is a
consequence of inadequate prior data preprocessing. 
The rank ordering distributes the data evenly
along the $x$-axis. A plot in which the $x$-axis shows the average
intensities themselves is obtained by calling the \Robject{plot}
command with the argument \Robject{ranks=FALSE}.

The parameter estimation in \Robject{vsn} works in an iterative
manner.  To verify that the iterations have converged, you can call
the function \Robject{vsnPlotPar}.
<<nkid-iter,include=FALSE,fig=TRUE,width=8,height=4,results=hide>>=
par(mfrow=c(1,2))
vsnPlotPar(nkid, "offsets")
vsnPlotPar(nkid, "factors")
@
\myincfig{vsn-nkid-iter}{\textwidth}{Iteration trajectory of the calibration
and transformation parameters} The plots in Fig.~\ref{vsn-nkid-iter} show the
values of the estimated calibration and variance stabilization parameters on
the $y$-axis as a function of the iteration index. All curves should reach a
plateau before the last iteration. If this is not the case, the number of
iterations may be increased through the parameter \Robject{iter}.  It
could also indicate a data quality problem, see Section~\ref{sec.qc}.

The generalized log-ratios for this experiment
can be obtained for further processing through
<<nkid-histM,include=FALSE,fig=TRUE,results=hide>>=
M <- exprs(nkid)[,2] - exprs(nkid)[,1] 
hist(M, breaks=50, col="#d95f0e")
@
\myincfig{vsn-nkid-histM}{0.4\textwidth}{Histogram of generalized 
log-ratios for the kidney example data}
The histogram is shown in Fig.~\ref{vsn-nkid-iter}.

%------------------------------------------------------------
\section{Running vsn on data from multiple arrays 
(``single color normalization'')} 
%------------------------------------------------------------
The package includes example data from a series of 8 cDNA arrays 
on which different lymphoma were hybridized together with a reference 
cDNA~\cite{Alizadeh}.
<<lymphoma>>=
data(lymphoma)
dim(exprs(lymphoma))
pData(lymphoma)
@
The 16 columns of the \Robject{lymphoma} object contain the red and
green intensities, respectively, from the 8 slides, as shown in the
table. Thus, the CH1 intensities are in columns $1, 3, \ldots, 15$,
the CH2 intensities in columns $2, 4, \ldots, 16$.  We can call
\Robject{vsn} on all of them at once:
<<lym-sdmean1,results=hide>>=
lym <- vsn(lymphoma)
@
This calculation may take a while. 
<<lym-sdmean2,include=FALSE,fig=TRUE>>=
meanSdPlot(lym)
@
\myincfig{vsn-lym-sdmean2}{0.5\textwidth}{Standard deviation 
versus rank of the mean for the lymphoma example data}
Again, Fig.~\ref{vsn-lym-sdmean2} helps to visually verify that the
variance stabilization worked.  As above, we can obtain the
generalized log-ratios for each slide, by subtracting the common
reference intensities from those for the 8 samples:
<<lym-M,include=FALSE,fig=TRUE,width=8,height=4,results=hide>>=
refrs <- (1:8)*2-1
samps <- (1:8)*2
M <- exprs(lym)[,samps] - exprs(lym)[,refrs] 
colnames(M) <-  pData(lymphoma)[samps, "sample"]
A <- rowMeans(exprs(lym))
par(mfrow=c(1,2))
plot(A, M[,"CLL-13"], pch=".")
abline(h=0, col="red")
plot(A, M[,"DLCL-0032"], pch=".")
abline(h=0, col="red")
@
\myincfig{vsn-lym-M}{\textwidth}{Mean-difference plots for two slides 
from the lymphoma example data}
Fig.~\ref{vsn-lym-M} shows the analagon to the $M$-vs-$A$-plots
as described in reference~\cite{Dudoit578}. Note that in the left
scatterplot, there is a cloud of points at low intensities that is
concentrated slightly off the line $M=0$.  In the right scatterplot, a
similar cloud sits right on the $M=0$ line. This could be related to a
quality problem with the left slide (e.\,g. related to the PCR
amplification or the printing, see Section~\ref{sec.qc}).

%---------------------------------------------------------
\section{Running vsn on Affymetrix data} \label{affy}
%---------------------------------------------------------
The package \Rpackage{affy} provides excellent functionality for
reading and processing Affymetrix genechip data. To use
\Robject{vsn} for the calibration and transformation of the probe
intensities, a wrapper is provided that can be used within the data
processing routines of \Rpackage{affy}. See the documentation for the
package \Rpackage{affy} for more information about data structures and
other available methods. Affymetrix genechips preprocessing involves
the following steps:
(i) combining the perfect match (PM) and mismatch 
(MM) intensities into one number per probe,
(ii) calibrating,
(iii) transforming, and
(iv) summarizing.
\Robject{vsn} addresses the calibration and transformation. We can use 
the function \Robject{expresso} to run the whole process in one go:

%% FIXME
<<affy1,results=hide,eval=FALSE>>=
library("affy")
library("affydata")
data("Dilution")
## let affy know about vsn
normalize.AffyBatch.methods <- c(normalize.AffyBatch.methods, "vsn")
es1 = expresso(Dilution[, 1:2], 
               bg.correct       = FALSE,   ## bg correction is done by vsn
               normalize.method = "vsn",
               pmcorrect.method = "pmonly", 
               summary.method   = "medianpolish")
@

Here, we have ignored the MM values and used \Robject{medianpolish} for
summarization, as in the RMA method~\cite{RMA}. For comparison, let's 
calculate expression values using another normalization method.
The resulting plots are shown in Fig.~\ref{vsn-affy3}.

%%FIXME
<<affy2,results=hide,eval=FALSE>>=
es2 = expresso(Dilution[, 1:2], 
               bgcorrect.method = "rma",
               normalize.method = "quantiles", 
               pmcorrect.method = "pmonly",
               summary.method   = "medianpolish")
## extract expression values
x1 = exprs(es1)
x2 = exprs(es2) 
@ 

%%FIXME
<<dummy>>=
x1=x2=matrix(runif(1000), ncol=2)
@ 

<<affy3,include=FALSE,fig=TRUE,width=7,height=7>>=
## graphics output
par(mfrow=c(2,2), pch=".")

## scatter plot
plot(x1, main="vsn: chip 3 vs 4")
plot(x2, main="rma: chip 3 vs 4")

## rank(mean) - difference plot
ylim = c(-0.7, 0.7)
plot(rank(rowSums(x1)), diff(t(x1)), ylim=ylim, main="rank(mean) vs differences")
abline(h=0, col="red")

plot(rank(rowSums(x2)), diff(t(x2)), ylim=ylim, main="rank(mean) vs differences")
abline(h=0, col="red")
@

Note that while the values of \Rpackage{vsn} are normally represented on the
natural logarithmic scale, with the wrapper \Rfunction{normalize.AffyBatch.vsn}
they are transformed to the logarithm base 2 scale. This way
\Rfunction{normalize.AffyBatch.vsn} fits into the conventions of the
\Rpackage{expresso}-function.

\myincfig{vsn-affy3}{\textwidth}{\Robject{normalize.AffyBatch.vsn} example}

%---------------------------------------------------------
\section{Running vsn from the limma package} \label{limma}
%---------------------------------------------------------
\Robject{vsn} can be called from the limma package through the
function \Robject{normalizeBetweenArrays}:

<<limma1,eval=FALSE>>= 
library("limma")
MA <- normalizeBetweenArrays(RG, method="vsn")
@

Note that \Robject{RG} should contain raw intensities, i.\,e., prior
log-transformation or any normalization. The returned intensities and
log-ratios in \Robject{MA} are on the $\log-2$ scale, not the $\log-e$
scale as when \Robject{vsn} is called directly. Please see also the
help page for \Robject{normalizeBetweenArrays}.

For print-tip wise normalization, construct a function
\Robject{pinId} that calculates the print-tip ID (1...16) for every
spot:

<<limma2,eval=FALSE>>=
pinId <- function(x)
  unlist(lapply(1:(x$ngrid.r*x$ngrid.c), rep, x$nspot.r*x$nspot.c))
@

and call

<<limma3,eval=FALSE>>=
MA <- normalizeBetweenArrays(RG, method="vsn", strata=pinId(thelayout))
@

%---------------------------------------------------------------------
\section{The calibration parameters} 
%---------------------------------------------------------------------
If $y_{ki}$ is the matrix of uncalibrated data, with $k$ indexing the
rows and $i$ the columns, then the calibrated data $y_{ki}'$ is
obtained through scaling by $\lambda_{si}$ and shifting by $o_{si}$:
\begin{equation}\label{eq.cal}
y_{ki}' = \frac {y_{ki}-o_{si}}{\lambda_{si}},
\end{equation}
where $s\equiv s(k)$ is the so-called \textit{stratum} for probe $k$. In the
simplest case, there is only one stratum, i.\,e.\ the index $s$ is always
equal to 1, or may be omitted altogether. This amounts to assuming that 
that the data of all probes on an array were subject to the same 
systematic effects, such that an array-wide calibration is sufficient.

A model with multiple strata per array may be useful for spotted
arrays. For these, stratification may be according to
print-tip~\cite{Dudoit578} or PCR-plate~\cite{HSG2002}. For
oligonucleotide arrays, it may be useful to stratify the probes by
physico-chemical properties, e.\,g.\, to assume that probes of
different sequence composition attract systematically different levels
of unspecific background signal.

The transformation to a scale where the variance of the data is approximately
independent of the mean is 
\begin{equation}\label{eq.vs}
h_{ki} = \arsinh(a_0+b_0y_{ki}') 
  = \log\left(a_0+b_0y_{ki}'+\sqrt{\left(a_0+b_0y_{ki}'\right)^2+1}\right).
\end{equation}
Eqns.~(\ref{eq.cal}) and (\ref{eq.vs}) can be combined, so that the whole 
transformation is given by 
\begin{equation}\label{eq.transf}
h_{ki} = \arsinh(a_{si} + b_{si} y_{ki}). 
\end{equation}
Here, $a_{si}=a_0-b_0o_{si}/\lambda_{si}$ and $b_{si}=b_0/\lambda_{si}$ 
are the combined calibation and transformation parameters for probes from
stratum $s$ and sample $i$.

We can access the calibration and transformation parameters through
<<nkid-calib1>>=
prep <- preproc(description(nkid))
names(prep)
prep$vsnParams
@
% $ for ESS
The \Robject{description} slot of an \Rclass{exprSet} is an object of
class \Rclass{MIAME}, and may contain annotation data pertinent to the
experiment represented by the object. For an exprSet with $d$ sample 
and $n_s$ probe strata % (see Section~\ref{sec.strata}),
\Robject{prep\$vsnParams} is a numeric array with dimensions $(n_s, d, 2)$. 
\Robject{prep\$vsnParams[s, i, 1]} is what was called $a_{si}$ in
Eqn.~(\ref{eq.transf}), and
\Robject{prep\$vsnParams[s, i, 2]} is $b_{si}$. Compare the 
numbers printed above with the final values in Fig.~\ref{vsn-nkid-iter}.

%---------------------------------------------------------------------
\subsection{More on calibration} 
%---------------------------------------------------------------------
Now suppose the kidney example data were not that well measured, and 
the red channel had a baseline that was shifted by 500 and a scale 
that differed by a factor of $0.25$:
<<nkid-calib2>>=
bkid <- kidney
exprs(bkid)[,"red"] <- 0.25 * (500+exprs(bkid)[,"red"])
@
We can again call \Robject{vsn} on this data
<<nkid-calib-warn1,echo=FALSE,results=hide>>=
oldwarn <- options(warn=-1)
@
<<nkid-calib3,results=hide>>=
nbkid <- vsn(bkid)
<<nkid-calib4,fig=TRUE,include=FALSE,width=8,height=4>>=
par(mfrow=c(1,2))
plot(exprs(bkid),  main = "raw", pch = ".", log="xy")
plot(exprs(nbkid), main = "vsn", pch = ".")
preproc(description(nbkid))$vsnParams[1,,]
@
% $ for ESS
\myincfig{vsn-nkid-calib4}{\textwidth}{Scatterplots for badly biased 
data. Left hand side: raw data on log-log scale, right hand side: after 
calibration and transformation with vsn.}
<<nkid-calib-warn2,echo=FALSE,results=hide>>=
options(oldwarn)
rm(oldwarn)
@
The factor for the red channel is now about four times as large as
before.  The result is shown in Fig.~\ref{vsn-nkid-calib4}.


%-------------------------------------------------------------------
\section{Assessing vsn}
%-------------------------------------------------------------------
The function \Robject{vsn} is a parameter estimation algorithm that fits the
parameters for a certain model. In order to see how good the estimator is, we
can look at bias, variance, sample size dependence, robustness against model
misspecificaton and outliers. This is done in the document
\texttt{convergence.pdf}, which can be found in the \texttt{doc} subdirectory
of the package.

Practically, the more interesting question is how different microarray
calibration and data transformation methods compare to each other. For this,
one needs to specify a measure of goodness. One approach is to compare the
obtained values against a known truth. This can be done in controlled spike-in
experiments and in dilution series, which allow to systematically assess the
performance of the methods at different biologically relevant spike-in
concentrations. Like any statistical method, one can make different choices
with respect to the trade-off between bias and variance~\cite{Affycomp}.

Here, we focus on one particular aspect: the overall sensitivity and
specificity in detecting differential transcription. The following
type of analysis can be applied to any data set that contains
replicated measurements made on samples from biologically distinct,
known groups. The idea is that we compare the within-group variability
(among the biological replicates) to the between-group variability
(between different tissue types). The smaller the former and the
larger the latter, the better we may deem the performance of the
calibration and data transformation.

Here, as a measure of the relative size of between- and within-group
variability we take the size of the $t$-statistics.  The acceptable
use of CPU time and disk memory of a package vignette is limited, thus
here we stick to a very simple-minded calculation, and a small data
set. See Fig.~\ref{fig-comp} and the calculations below. Two
applications to larger data sets are described in
reference~\cite{HuberISMB2002}.  More sophisticated analyses can be
made by comparing not just the distributions of $t$-statistics, but
for example, the estimated false discovery rates, using different test
statistics. You are encouraged to try this out with your own data.
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{vsn-comp}
\caption{\label{fig-comp}Left hand side: $x$-axis -- generalized
log-ratios for slide 1 from \Robject{vsn}, $y$-axis -- log-ratios
for slide 1 after global median normalization. For most genes, the two
are the same, but in some cases the generalized log-ratio is smaller.
It is never larger. This demonstrates the \textit{ratio shrinkage} by
the variance stabilization. Right hand side: quantile-quantile-plot of
the $t$-statistic for the comparison between the 4 slides with CLL and
the 4 with DLCL. The $t$-statistics from \Robject{vsn} are larger,
i.\,e.\ it compares more favorable with respect to the relative size
of between- and within-group variability.}
\end{center}
\end{figure}

<<marraynorm,results=hide>>=
library("marray")
mr <- new('marrayRaw', 
          maGf=exprs(lymphoma)[,refrs], 
          maRf=exprs(lymphoma)[,samps],
          maLayout=new('marrayLayout', maNgr=4, maNgc=4, maNsr=24, maNsc=24))
mn <- maNorm(mr, norm="median", echo=TRUE)
@
<<comp,results=hide,fig=TRUE,width=8,height=4,include=FALSE>>=
par(mfrow=c(1,2))
library("multtest")
plot(M[,1], mn@maM[,1]*log(2), xlab="M (vsn)", ylab="M (global median)", main="slide 1", pch=".")
abline(a=0,b=1,col="blue")
classlabel <- regexpr("CLL",colnames(M)) > 0
t1 <- mt.teststat(M, classlabel)
t2 <- mt.teststat(mn@maM, classlabel)
qqplot(t1, t2, xlab="t (vsn)", ylab="t (global median)", main="QQ plot", pch=".")
abline(a=0,b=1,col="blue")
@

%---------------------------------------------------------
\section{Quality assessment}\label{sec.qc}
%---------------------------------------------------------
\Robject{vsn} makes some assumptions about your data that need to
hold if it is to produce meaningful results. We have found them
appropriate for many microarray experiments, but it is your
responsibility to make sure that they hold for your data.

First, \Robject{vsn} assumes that the measured signal $y_{ik}$
increases, to sufficient approximation, proportionally to the mRNA
abundance $c_{ik}$ of gene $k$ on the $i$-th array, or on the $i$-th
color channel:
\begin{equation}\label{assumption.1} 
y_{ik}\approx a_i + b_i b_k c_{ik}.  
\end{equation} 
For a series of $d$ single-color arrays such as Affymetrix arrays
or cDNA nylon membranes, $i=1,\ldots,d$, and the different factors 
$b_i$ reflect the different initial amounts of sample mRNA, or different
overall reverse transcription, hybridization and detection efficiencies. 
The probe affinity $b_k$ contains factors that affect
all measurements with probe $k$ in the same manner, such as
sequence-specific labelling 
efficiency. The $b_k$ are assumed to be the same across all arrays.
There can be a non-zero overall offset $a_i$ for each color channel.
For a two-color cDNA array, $i=1,2$, and the $b_i$ take into account
the different overall efficiencies of the two dyes\footnote{% 
It has been reported that for some genes the dye bias is different from 
gene to gene, such that the proportionality factor does not simply factorize 
as in~(\ref{assumption.1}). As long as this only occurs sporadically, this 
should not have much effect on the estimation of the calibration and 
variance stabilization parameters. Further, by using an appropriate 
experimental design such as color-swap or reference design, the effects of 
gene-specific dye-biases to subsequent analyses can also be reduced.}.

\paragraph{Systematic effects associated with print-tip, PCR, or 
probe-sequence} 
Equation~\ref{assumption.1} can be generalized to
\begin{equation}\label{assumption.2} 
y_{ik}\approx a_{is} + b_{is} b_k c_{ik}.  
\end{equation} 
that is, the background term $a_{is}$ and the gain factor $b_{is}$ can
be different for different groups $s$ of probes on an array. For example,
with cDNA microarray data, it could be advantageous to fit different parameters 
for each print-tip group of spots, or for groups of spots whose DNA was 
PCR--amplified and stored in the same microtitre plate. For Affymetrix chips, 
one can find systematic dependences of the affinities $b_{is}$ or the 
background terms $a_{is}$ on the probe sequence.
This can be addressed by using the \Robject{strata} argument of 
the function \Robject{vsn}.

Situations in which the assumptions~(\ref{assumption.1}) or ~(\ref{assumption.2}) 
are violated include:

\paragraph{Saturation.} The biochemical reactions and/or the photodetection 
can be run in such a manner that saturation effects occur.
It may be possible to rescue such data by using non-linear transformations. 
Alternatively, it is recommended that the experimental parameters are 
chosen to avoid saturation.

\paragraph{Batch effects.} The probe affinities $b_k$ may differ between
different manufacturing batches of arrays due, e.g., to different
qualities of DNA amplification or printing. \Robject{vsn} cannot be
used to simultaneously calibrate and transform data from different
batches.

How to reliably diagnose and deal with such violations is beyond the scope 
of this vignette; see the references for more~\cite{Dudoit578,HSG2002}. 

\paragraph{Variance.} A further assumption that \Robject{vsn} makes is that 
the measurement error (more exactly: the variance) is the sum of two
contributions: an additive component that has roughly the same size
for all probes on an array, and a multiplicative component that is
roughly proportional in size to the signal's true value, with a
proportionality factor (called the \textit{coefficient of variation})
that is the same for all genes~\cite{RockeDurbin2001}.

\paragraph{Most genes unchanged assumption.} 
\Robject{vsn} assumes that only a minority (less than half) of genes on the
arrays is detectably differentially transcribed across the experiments. If it
is safe to assume that a smaller fraction of genes is non-negligibly
differentially transcribed, the efficiency of the estimation can be improved
by increasing the parameter \Robject{lts.quantile} from its default value
of 0.5 to a value between 0.5 and 1.

\paragraph{Processing biases.} 
Image analysis software for cDNA arrays typically estimates a
\textit{local background} associated with each probe intensity. For
Affymetrix arrays, the intensities from {mismatch} probes are thought
to represent the level of non-specific signal. In both cases, the raw
probe intensities may be \textit{adjusted} by subtracting these
background estimates. Some software packages, however, bias the
adjustment through rules based on the data values. For example,
Affymetrix' MAS 5.0 software uses the mismatch intensity only if it is
smaller than the probe's intensity, and otherwise employs a heuristic
to make sure that the net intensities always remain positive. As a
consequence, the intensities are systematically over-estimated, and
cannot be used with \Robject{vsn}. For Affymetrix data, we recommend
to use \Robject{vsn} on the probe intensities from the "CEL
file". For cDNA data, we recommend to use only background adjustment
procedures that estimate the background independent of the observed
foreground intensity.

<<setdown,echo=FALSE,results=hide>>=
options(oldopt)
@

\begin{thebibliography}{10}

\bibitem{HuberISMB2002}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Variance stablization applied to microarray data calibration and to
  quantification of differential expression.
\newblock \textit{Bioinformatics}, 18:S96--S104, 2002.

\bibitem{HSG2002}
W. Huber, A. von Heydebreck, and M. Vingron.
\newblock Analysis of microarray gene expression data.
\newblock To appear in the \textit{Handbook of Statistical Genetics}, 2003.
Eds.: D. J. Balding, M. Bishop, C. Cannings. 
John Wiley \& Sons, Inc., 

\bibitem{HuberSAGMB2003}
W. Huber, A. von Heydebreck, H. {S\"ultmann}, A. Poustka, and M. Vingron.
\newblock Parameter estimation for the calibration and variance stabilization 
of microarray data.
\newblock \textit{Statistical Applications in Genetics and Molecular Biology}, 
Vol. 2: No. 1, Article 3, 2003. 
http://www.bepress.com/sagmb/vol2/iss1/art3

\bibitem{RockeDurbin2001}
David~M. Rocke and Blythe Durbin.
\newblock A model for measurement error for gene expression analysis.
\newblock \textit{Journal of Computational Biology}, 8:557--569, 2001.

\bibitem{Dudoit578}
S. Dudoit, Y.~H. Yang, T.~P. Speed, and M.~J. Callow.
\newblock Statistical methods for identifying differentially expressed genes in
  replicated {cDNA} microarray experiments.
\newblock \textit{Statistica Sinica}, 12:111--139, 2002.

\bibitem{Alizadeh}
A.~A. Alizadeh et al.
\newblock Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling.
\newblock \textit{Nature}, 403:503--511, 2000.

\bibitem{Affycomp}
L.~M. Cope, R.~A. Irizarry, H.~A. Jaffee, Z.~Wu, and T.~P. Speed.
\newblock A Benchmark for Affymetrix GeneChip Expression Measures.
\newblock \textit{Bioinformatics}, 20:323--331, 2004.

\bibitem{RMA}
R.~A. Irizarry, B.~Hobbs, F.~Collin, Y.~D. Beazer-Barclay, K.~J. Antonellis, 
U.~Scherf, and T.~P. Speed. \newblock Exploration, normalization, and 
summaries of high density oligonucleotide array probe level data.
\newblock \textit{Biostatistics} 4:249--264, 2003.

\end{thebibliography}
\end{document}


